{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9430984,"sourceType":"datasetVersion","datasetId":5729649}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Set directories\nimport os\nws_dir = '/kaggle/input'\ndataset_dir = os.path.join(ws_dir, 'dataset01')\nfaces_dir = os.path.join(dataset_dir, 'faces')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-24T12:30:00.588137Z","iopub.execute_input":"2024-09-24T12:30:00.588820Z","iopub.status.idle":"2024-09-24T12:30:00.599245Z","shell.execute_reply.started":"2024-09-24T12:30:00.588784Z","shell.execute_reply":"2024-09-24T12:30:00.598339Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport numpy as np\n\nimages = []\nlabels = []\n\n# Loop over each person directory in the faces directory\nfor person_name in os.listdir(faces_dir):\n    person_dir = os.path.join(faces_dir, person_name)\n\n    # Check if it is a directory (and not a file)\n    if os.path.isdir(person_dir):\n        # Loop over each image in the person's directory\n        for image_name in os.listdir(person_dir):\n            image_path = os.path.join(person_dir, image_name)\n\n            # Load image using OpenCV\n            image = cv2.imread(image_path)\n\n            # Optionally resize images to a standard size (e.g., 224x224)\n            image = cv2.resize(image, (224, 224))\n\n            # Convert the image to RGB (OpenCV loads images in BGR format by default)\n            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n            # Append image and corresponding label to lists\n            images.append(image)\n            labels.append(person_name)  # The person's name is used as the label\n\n# Convert lists to NumPy arrays\nimages_np = np.array(images)\nlabels_np = np.array(labels)\n\n# Verify the shapes\nprint(f'Images shape: {images_np.shape}')  # (num_images, 224, 224, 3)\nprint(f'Labels shape: {labels_np.shape}')  # (num_images,)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-24T12:30:00.600853Z","iopub.execute_input":"2024-09-24T12:30:00.601157Z","iopub.status.idle":"2024-09-24T12:30:20.158900Z","shell.execute_reply.started":"2024-09-24T12:30:00.601125Z","shell.execute_reply":"2024-09-24T12:30:20.157850Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Images shape: (2562, 224, 224, 3)\nLabels shape: (2562,)\n","output_type":"stream"}]},{"cell_type":"code","source":"from tensorflow.keras.applications.vgg19 import preprocess_input\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nimport numpy as np\n\n# Assuming images_np and labels_np are provided\n# images_np.shape = (num_samples, height, width, channels)\n# labels_np.shape = (num_samples,)\n\n# Preprocess images for VGG19\nimages_np_preprocessed = preprocess_input(images_np)\n\n# One-hot encode labels\none_hot_encoder = OneHotEncoder(sparse=False)\nlabels_np_onehot = one_hot_encoder.fit_transform(labels_np.reshape(-1, 1))\n\n# Split into training, validation, and test sets\nX_train, X_temp, y_train, y_temp = train_test_split(images_np_preprocessed, labels_np_onehot, test_size=0.3, random_state=42)\nX_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n\nprint(f\"Train set: {X_train.shape}, {y_train.shape}\")\nprint(f\"Validation set: {X_val.shape}, {y_val.shape}\")\nprint(f\"Test set: {X_test.shape}, {y_test.shape}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-24T12:30:49.542081Z","iopub.execute_input":"2024-09-24T12:30:49.542467Z","iopub.status.idle":"2024-09-24T12:31:05.854796Z","shell.execute_reply.started":"2024-09-24T12:30:49.542429Z","shell.execute_reply":"2024-09-24T12:31:05.853787Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train set: (1793, 224, 224, 3), (1793, 31)\nValidation set: (384, 224, 224, 3), (384, 31)\nTest set: (385, 224, 224, 3), (385, 31)\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers, models, regularizers\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nclass CenterLossLayer(tf.keras.layers.Layer):\n    def __init__(self, num_classes, embedding_dim, margin=1.0, alpha=0.001, **kwargs):\n        super(CenterLossLayer, self).__init__(**kwargs)\n        self.num_classes = num_classes\n        self.embedding_dim = embedding_dim\n        self.margin = tf.cast(margin, tf.float32)\n        self.alpha = alpha  # EMA smoothing factor\n        self.distance = 0.1  # The length between P1 and P2\n\n        # Initialize center_p1 randomly using a normal distribution\n        self.centers_P1 = self.add_weight(name='centers_P1',\n                                          shape=(num_classes, embedding_dim),\n                                          initializer='random_normal',\n                                          trainable=False,\n                                          dtype=tf.float32)\n\n        # Create center_p2 without initialization\n        self.centers_P2 = self.add_weight(name='centers_P2',\n                                          shape=(num_classes, embedding_dim),\n                                          initializer='zeros',\n                                          trainable=False,\n                                          dtype=tf.float32)\n\n    def build(self, input_shape):\n        # Generate a random unit vector direction for center_p2\n        random_direction = tf.random.normal((self.num_classes, self.embedding_dim))\n        unit_vector = random_direction / tf.norm(random_direction, axis=1, keepdims=True)  # Normalize\n\n        # Assign center_p2 to be 'distance' units away from center_p1\n        center_p2_value = self.distance * unit_vector\n        self.centers_P2.assign(center_p2_value)\n\n        super(CenterLossLayer, self).build(input_shape)\n    \n    def call(self, inputs):\n        embeddings, labels = inputs\n\n        # Ensure embeddings and labels are float32\n        embeddings = tf.cast(embeddings, tf.float32)\n        labels = tf.argmax(labels, axis=-1, output_type=tf.int32)\n\n        # Step 1: Compute the midpoint for each class (mean of embeddings for each class)\n        batch_midpoint = tf.math.unsorted_segment_mean(embeddings, labels, num_segments=self.num_classes)\n\n        # Step 2: Calculate the variance for each class\n        squared_diff = tf.square(embeddings - tf.gather(batch_midpoint, labels))\n        batch_variance = tf.math.unsorted_segment_mean(squared_diff, labels, num_segments=self.num_classes)\n\n        # Step 3: Compute the standard deviation (sqrt of variance)\n        batch_stddev = tf.sqrt(batch_variance)\n\n        # Step 4: Position centers_P1 and centers_P2 around the midpoint\n        # Center_P1 closer to the midpoint, Center_P2 further from the midpoint\n        batch_centers_P1 = batch_midpoint - 0.5 * batch_stddev  # Center_P1 inside dense region\n        batch_centers_P2 = batch_midpoint + 0.5 * batch_stddev  # Center_P2 outside dense region\n\n        # Gather the centers corresponding to the labels\n        batch_centers_P1_gathered = tf.gather(batch_centers_P1, labels)\n        batch_centers_P2_gathered = tf.gather(batch_centers_P2, labels)\n\n        # Step 5: Update centers using EMA (Exponential Moving Average)\n        center_updates_P1 = tf.scatter_nd(tf.expand_dims(labels, 1),\n                                          batch_centers_P1_gathered,\n                                          shape=tf.shape(self.centers_P1))\n        center_updates_P2 = tf.scatter_nd(tf.expand_dims(labels, 1),\n                                          batch_centers_P2_gathered,\n                                          shape=tf.shape(self.centers_P2))\n\n        # EMA update for centers_P1 and centers_P2\n        new_centers_P1 = self.centers_P1 * (1 - self.alpha) + center_updates_P1 * self.alpha\n        new_centers_P2 = self.centers_P2 * (1 - self.alpha) + center_updates_P2 * self.alpha\n\n        # Assign updated centers\n        self.centers_P1.assign(new_centers_P1)\n        self.centers_P2.assign(new_centers_P2)\n\n        # Step 6: Compute distances to all class segments for each embedding\n        distances = self.compute_distance_to_segment_all_classes(embeddings)\n\n        # Step 7: Get the correct distances by indexing with labels\n        correct_distances = tf.gather_nd(distances, tf.expand_dims(labels, axis=-1), batch_dims=1)\n\n        # Step 8: Mask out correct class distances and find the minimum incorrect distance\n        mask = tf.one_hot(labels, depth=self.num_classes, on_value=False, off_value=True)\n        masked_distances = tf.where(mask, distances, tf.fill(tf.shape(distances), float('inf')))\n        min_incorrect_distances = tf.reduce_min(masked_distances, axis=1)\n\n        # Step 9: Compute the loss\n        incorrect_loss = tf.maximum(0.0, self.margin - min_incorrect_distances)\n        center_loss = tf.reduce_mean(tf.square(correct_distances))\n\n        return center_loss + tf.reduce_mean(incorrect_loss)\n\n\n    def compute_distance_to_segment_all_classes(self, embeddings):\n        \"\"\"\n        Compute the Euclidean distance from each embedding to the nearest point on the line segment\n        defined by P1 and P2 for each class.\n        \"\"\"\n        # Get P1 and P2 for all classes\n        P1 = self.centers_P1\n        P2 = self.centers_P2\n\n        # Vector from P1 to P2 for all classes\n        P1_P2 = P2 - P1\n\n        # Expand dims for broadcasting\n        P1 = tf.expand_dims(P1, axis=0)\n        P2 = tf.expand_dims(P2, axis=0)\n        P1_P2 = tf.expand_dims(P1_P2, axis=0)\n        embeddings = tf.expand_dims(embeddings, axis=1)\n\n        # Vector from P1 to the embeddings\n        P1_emb = embeddings - P1\n\n        # Project embeddings onto the line segment\n        proj = tf.reduce_sum(P1_emb * P1_P2, axis=2, keepdims=True) / tf.maximum(tf.reduce_sum(P1_P2 ** 2, axis=2, keepdims=True), 1e-8)\n\n        # Clamp projection to the range [0, 1] to restrict to the segment\n        proj_clamped = tf.clip_by_value(proj, 0.0, 1.0)\n\n        # Compute the nearest point on the line segment\n        nearest_point = P1 + proj_clamped * P1_P2\n\n        # Compute the Euclidean distance to the nearest point on the segment\n        distances = tf.norm(embeddings - nearest_point, axis=2)\n\n        return distances\n\ndef build_vgg19_center_loss(input_shape, num_classes, embedding_dim, dropout_rate, weight_decay):\n    # Define input layers\n    inputs = layers.Input(shape=input_shape, name='input')\n    labels_input = layers.Input(shape=(num_classes,), name='labels_input', dtype='float32')\n\n    # Define VGG19 backbone (without the top layers)\n    base_model = tf.keras.applications.VGG19(include_top=False, input_shape=input_shape, weights='imagenet')\n\n    for layer in base_model.layers[:15]:  # Freeze the first 15 layers (you can adjust this number)\n        layer.trainable = False\n    \n    # Flatten the output of the VGG19 backbone\n    x = base_model.output\n    x = layers.Flatten()(x)\n    \n    x = layers.Dense(1231, activation='swish', kernel_regularizer=regularizers.l2(weight_decay), bias_regularizer=regularizers.l2(0.01) )(x)\n    x = layers.Dropout(dropout_rate)(x)\n    x = layers.Dense(300, activation='swish', kernel_regularizer=regularizers.l2(weight_decay), bias_regularizer=regularizers.l2(0.01) )(x)\n    x = layers.Dropout(dropout_rate)(x)\n    x = layers.Dense(75, activation='swish', kernel_regularizer=regularizers.l2(weight_decay), bias_regularizer=regularizers.l2(0.01) )(x)\n    x = layers.Dropout(dropout_rate)(x)\n    x = layers.Dense(1003, activation='swish', kernel_regularizer=regularizers.l2(weight_decay), bias_regularizer=regularizers.l2(0.01) )(x)\n    x = layers.Dense(embedding_dim, activation='swish')(x)\n\n    # Define the embedding model\n    embedding_model = models.Model(inputs=base_model.input, outputs=x, name='embedding_model')\n\n    # Generate embeddings for the inputs\n    embedding = embedding_model(inputs)\n\n    # Define logits for classification using the embedding\n    logits = layers.Dense(num_classes, activation='softmax', name='classification_layer')(embedding)\n    # logits = tf.keras.layers.Lambda(lambda x: x / 10)(logits)  # Example scaling\n    # logits = tf.keras.layers.Activation('softmax')(logits)\n\n    # Define the custom center loss layer\n    center_loss_layer = CenterLossLayer(num_classes=num_classes, embedding_dim=embedding_dim)\n    center_loss_output = center_loss_layer([embedding, labels_input])\n\n    # Define the full model with classification and center loss\n    full_model = models.Model(\n        inputs=[inputs, labels_input],\n        outputs=[logits, center_loss_output],\n        name='full_model'\n    )\n\n    return embedding_model, full_model\n\ndef train_and_evaluate(model, train_generator, val_generator, steps_per_epoch, validation_steps, epochs, center_loss_weight, learning_rate):\n    optimizer = tf.keras.optimizers.RMSprop(learning_rate)\n\n    history = {\n        \"train_loss\": [],\n        \"train_class_loss\": [],\n        \"train_center_loss\": [],\n        \"train_acc\": [],\n        \"val_class_loss\": [],\n        \"val_center_loss\": [],\n        \"val_acc\": []\n    }\n\n    @tf.function\n    def train_step(inputs, labels):\n        with tf.GradientTape() as tape:\n            logits, center_loss = model([inputs, labels], training=True)\n            classification_loss = tf.keras.losses.CategoricalCrossentropy()(labels, logits)\n            total_loss = classification_loss + center_loss_weight * center_loss\n\n        gradients = tape.gradient(total_loss, model.trainable_variables)\n        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n\n        predictions = tf.argmax(logits, axis=-1)\n        labels_true = tf.argmax(labels, axis=-1)\n        train_acc = tf.reduce_mean(tf.cast(tf.equal(predictions, labels_true), tf.float32))\n\n        return total_loss, classification_loss, center_loss, train_acc\n\n    @tf.function\n    def eval_step(inputs, labels):\n        logits, center_loss = model([inputs, labels], training=False)\n        classification_loss = tf.keras.losses.CategoricalCrossentropy()(labels, logits)\n\n        predictions = tf.argmax(logits, axis=-1)\n        labels_true = tf.argmax(labels, axis=-1)\n        accuracy = tf.reduce_mean(tf.cast(tf.equal(predictions, labels_true), tf.float32))\n\n        return classification_loss, center_loss, accuracy\n\n    for epoch in range(epochs):\n        print(f\"Epoch {epoch+1}/{epochs}\")\n\n        # Training loop\n        epoch_loss, epoch_class_loss, epoch_center_loss, epoch_acc = 0, 0, 0, 0\n        for step in range(steps_per_epoch):\n            inputs_batch, labels_batch = next(train_generator)\n            loss, class_loss, center_loss, acc = train_step(inputs_batch, labels_batch)\n            epoch_loss += loss\n            epoch_class_loss += class_loss\n            epoch_center_loss += center_loss\n            epoch_acc += acc\n\n        epoch_loss /= steps_per_epoch\n        epoch_class_loss /= steps_per_epoch\n        epoch_center_loss /= steps_per_epoch\n        epoch_acc /= steps_per_epoch\n\n        print(f\"Train Loss: {epoch_loss:.4f}, Class Loss: {epoch_class_loss:.4f}, Center Loss: {epoch_center_loss:.4f}, Acc: {epoch_acc:.4f}\")\n\n        history[\"train_loss\"].append(epoch_loss)\n        history[\"train_class_loss\"].append(epoch_class_loss)\n        history[\"train_center_loss\"].append(epoch_center_loss)\n        history[\"train_acc\"].append(epoch_acc)\n\n        # Validation loop\n        val_class_loss, val_center_loss, val_acc = 0, 0, 0\n        for step in range(validation_steps):\n            inputs_batch, labels_batch = next(val_generator)\n            class_loss, center_loss, acc = eval_step(inputs_batch, labels_batch)\n            val_class_loss += class_loss\n            val_center_loss += center_loss\n            val_acc += acc\n\n        val_class_loss /= validation_steps\n        val_center_loss /= validation_steps\n        val_acc /= validation_steps\n\n        print(f\"Val Class Loss: {val_class_loss:.4f}, Val Center Loss: {val_center_loss:.4f}, Val Acc: {val_acc:.4f}\")\n\n        history[\"val_class_loss\"].append(val_class_loss)\n        history[\"val_center_loss\"].append(val_center_loss)\n        history[\"val_acc\"].append(val_acc)\n\n    return history\n\n# Initialize ImageDataGenerator with augmentation options (without rescaling)\ntrain_datagen = ImageDataGenerator(\n    rotation_range=20,           # Randomly rotate images by 20 degrees\n    width_shift_range=0.2,       # Randomly shift images horizontally\n    height_shift_range=0.2,      # Randomly shift images vertically\n    shear_range=0.2,             # Shear transformation\n    zoom_range=0.2,              # Zoom in/out\n    horizontal_flip=True,        # Random horizontal flipping\n    fill_mode='nearest'          # Filling pixels after transformations\n)\n\n# Example usage with specified values\ninput_shape = (224, 224, 3)        # Input shape for images (224x224 RGB)\nnum_classes = 31                   # Number of classes in the dataset\nembedding_dim = 768              # Dimensionality of the embedding space\ndropout_rate = 0.1               # Dropout rate for regularization\nweight_decay = 0.05 #0.005            # L2 regularization weight\ncenter_loss_weight = 0.01 #0.0001          # Weight for center loss\nlearning_rate = 1e-4               # Learning rate for the optimizer\nbatch_size = 32                    # Batch size for training\nepochs = 30                      # Number of epochs to train\n\nval_datagen = ImageDataGenerator()  # No additional augmentations for validation\n\n# Load and augment training data\ntrain_generator = train_datagen.flow(X_train, y_train, batch_size=batch_size)\n\n# Load validation data\nval_generator = val_datagen.flow(X_val, y_val, batch_size=batch_size)\n\nsteps_per_epoch = len(X_train) // batch_size\nvalidation_steps = len(X_val)  // batch_size\n\n# Build the model using VGG19 and center loss\nembedding_model, full_model = build_vgg19_center_loss(input_shape, num_classes, embedding_dim, dropout_rate, weight_decay)\n# Train the model using data generators\nhistory = train_and_evaluate(full_model, train_generator, val_generator, steps_per_epoch, validation_steps, epochs, center_loss_weight, learning_rate)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-23T22:43:30.543217Z","iopub.execute_input":"2024-09-23T22:43:30.543779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = train_and_evaluate(full_model, train_generator, val_generator, steps_per_epoch, validation_steps, epochs, center_loss_weight, learning_rate)","metadata":{"execution":{"iopub.status.busy":"2024-09-23T22:59:04.831657Z","iopub.execute_input":"2024-09-23T22:59:04.832642Z","iopub.status.idle":"2024-09-23T23:14:18.632775Z","shell.execute_reply.started":"2024-09-23T22:59:04.832596Z","shell.execute_reply":"2024-09-23T23:14:18.631778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.manifold import TSNE\nfrom sklearn.preprocessing import LabelEncoder\nfrom matplotlib import cm\nfrom matplotlib.colors import ListedColormap\n\n\n#embedding_model = models.Model(inputs=model.inputs[0], outputs=model.get_layer('embeddings').output)\n\n# Generate embeddings with 'training=False'\nembeddings = embedding_model.predict(images_np_preprocessed)\n\n# Sample image embeddings and labels\n# image_embeddings = ... (your embeddings)\n# labels_np = ... (your string labels)\n\n# Convert string labels to numeric labels\nlabel_encoder = LabelEncoder()\nnumeric_labels = label_encoder.fit_transform(labels_np)\n\n# Use t-SNE to reduce the embedding space to 2D for visualization\ntsne = TSNE(n_components=2, random_state=42)\nembeddings_2d = tsne.fit_transform(embeddings)  # Use your actual embeddings here\n\n# Create a custom color map to support 31 classes\ncolors = cm.get_cmap('tab20b', 31)  # 'tab20b' offers a distinct palette; we can define 31 colors explicitly\n\n# Plot the 2D embeddings with color based on numeric labels\nplt.figure(figsize=(10, 10))\nscatter = plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], \n                      c=numeric_labels, cmap=colors, s=20)  # Decreased marker size (s=20)\n\n# Add a color legend\nlegend1 = plt.legend(*scatter.legend_elements(), title=\"Person\")\nplt.gca().add_artist(legend1)\n\n# Set plot details\nplt.title('t-SNE of Image Embeddings (Color-coded)')\nplt.xlabel('Component 1')\nplt.ylabel('Component 2')\n\n# Show the plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-09-23T23:14:54.749341Z","iopub.execute_input":"2024-09-23T23:14:54.749766Z","iopub.status.idle":"2024-09-23T23:15:22.690844Z","shell.execute_reply.started":"2024-09-23T23:14:54.749726Z","shell.execute_reply":"2024-09-23T23:15:22.689899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from collections import defaultdict\n\n# Convert string labels to numeric labels\nlabel_encoder = LabelEncoder()\nnumeric_labels = label_encoder.fit_transform(labels_np)\n\n# Use t-SNE to reduce the embedding space to 2D for visualization\ntsne = TSNE(n_components=2, random_state=42)\nembeddings_2d = tsne.fit_transform(embeddings)  # Use your actual embeddings here\n\n# Create a custom color map to support 31 classes\ncolors = cm.get_cmap('tab20b', 31)  # 'tab20b' offers a distinct palette; we can define 31 colors explicitly\n\n# Plot the 2D embeddings with color based on numeric labels\nplt.figure(figsize=(12, 12))\nscatter = plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], \n                      c=numeric_labels, cmap=colors, s=50)  # Adjust marker size (s=50)\n\n# To store average position of each cluster\ncluster_centers = defaultdict(list)\n\n# Gather all points belonging to the same class\nfor i, label in enumerate(numeric_labels):\n    cluster_centers[label].append(embeddings_2d[i])\n\n# Annotate each cluster with one label\nfor label, points in cluster_centers.items():\n    cluster_points = np.array(points)\n    # Find the centroid of the cluster\n    centroid = np.mean(cluster_points, axis=0)\n    # Get the original string label for the cluster\n    label_name = label_encoder.inverse_transform([label])[0]\n    # Annotate at the centroid\n    plt.text(centroid[0], centroid[1], label_name, fontsize=12, ha='center', va='center', \n             bbox=dict(facecolor='white', alpha=0.6, edgecolor='none'))\n\n# Add a color legend\nlegend1 = plt.legend(*scatter.legend_elements(), title=\"Person\")\nplt.gca().add_artist(legend1)\n\n# Set plot details\nplt.title('t-SNE of Image Embeddings with One Label per Cluster')\nplt.xlabel('Component 1')\nplt.ylabel('Component 2')\n\n# Show the plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-09-23T23:23:28.316078Z","iopub.execute_input":"2024-09-23T23:23:28.316480Z","iopub.status.idle":"2024-09-23T23:23:37.763051Z","shell.execute_reply.started":"2024-09-23T23:23:28.316439Z","shell.execute_reply":"2024-09-23T23:23:37.762131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## KDE","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers, models, regularizers\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models, regularizers\nimport numpy as np\n\nclass KDELossLayer(tf.keras.layers.Layer):\n    def __init__(self, bandwidth=1.0, **kwargs):\n        super(KDELossLayer, self).__init__(**kwargs)\n        self.bandwidth = tf.cast(bandwidth, tf.float32)\n\n    def call(self, inputs):\n        embeddings, labels = inputs\n\n        # Ensure embeddings are float32\n        embeddings = tf.cast(embeddings, tf.float32)\n\n        # Convert labels to one-hot encoding\n        labels = tf.argmax(labels, axis=-1, output_type=tf.int32)\n        one_hot_labels = tf.one_hot(labels, depth=tf.reduce_max(labels) + 1)\n\n        # Compute pairwise distances for all embeddings\n        pairwise_dists = tf.norm(\n            tf.expand_dims(embeddings, 1) - tf.expand_dims(embeddings, 0), axis=-1\n        )\n\n        # Gaussian kernel for all distances\n        kde_density = tf.exp(-pairwise_dists**2 / (2 * self.bandwidth**2))\n\n        # For each class, apply the mask to isolate class members\n        mask = tf.matmul(one_hot_labels, tf.transpose(one_hot_labels))\n        \n        # Avoid self-contribution by masking out diagonal elements\n        mask_off_diagonal = tf.linalg.set_diag(mask, tf.zeros(tf.shape(mask)[0]))\n        \n        # Compute KDE loss for each class\n        kde_class_density = tf.reduce_sum(kde_density * mask_off_diagonal, axis=-1)\n\n        # Compute log of KDE density and avoid log(0)\n        kde_loss = -tf.reduce_mean(tf.math.log(kde_class_density + 1e-8))\n        \n        return kde_loss\n\n\n\ndef build_vgg19_kde_loss(input_shape, num_classes, embedding_dim, dropout_rate, weight_decay):\n    # Define input layers\n    inputs = layers.Input(shape=input_shape, name='input')\n    labels_input = layers.Input(shape=(num_classes,), name='labels_input', dtype='float32')\n\n    # Define VGG19 backbone (without the top layers)\n    base_model = tf.keras.applications.VGG19(include_top=False, input_shape=input_shape, weights='imagenet')\n\n    for layer in base_model.layers[:15]:  # Freeze the first 15 layers (you can adjust this number)\n        layer.trainable = False\n    \n    # Flatten the output of the VGG19 backbone\n    x = base_model.output\n    x = layers.Flatten()(x)\n    \n    x = layers.Dense(1231, activation='swish', kernel_regularizer=regularizers.l2(weight_decay), bias_regularizer=regularizers.l2(0.01))(x)\n    x = layers.Dropout(dropout_rate)(x)\n    x = layers.Dense(300, activation='swish', kernel_regularizer=regularizers.l2(weight_decay), bias_regularizer=regularizers.l2(0.01))(x)\n    x = layers.Dropout(dropout_rate)(x)\n    x = layers.Dense(75, activation='swish', kernel_regularizer=regularizers.l2(weight_decay), bias_regularizer=regularizers.l2(0.01))(x)\n    x = layers.Dropout(dropout_rate)(x)\n    x = layers.Dense(1003, activation='swish', kernel_regularizer=regularizers.l2(weight_decay), bias_regularizer=regularizers.l2(0.01))(x)\n    x = layers.Dense(embedding_dim, activation='swish')(x)\n\n    # Define the embedding model\n    embedding_model = models.Model(inputs=base_model.input, outputs=x, name='embedding_model')\n\n    # Generate embeddings for the inputs\n    embedding = embedding_model(inputs)\n\n    # Define logits for classification using the embedding\n    logits = layers.Dense(num_classes, activation='softmax', name='classification_layer')(embedding)\n\n    # Define the custom KDE loss layer\n    kde_loss_layer = KDELossLayer()\n    kde_loss_output = kde_loss_layer([embedding, labels_input])\n\n    # Define the full model with classification and KDE loss\n    full_model = models.Model(\n        inputs=[inputs, labels_input],\n        outputs=[logits, kde_loss_output],\n        name='full_model'\n    )\n\n    return embedding_model, full_model\n\ndef train_and_evaluate(model, train_generator, val_generator, steps_per_epoch, validation_steps, epochs, center_loss_weight, learning_rate):\n    optimizer = tf.keras.optimizers.RMSprop(learning_rate)\n\n    history = {\n        \"train_loss\": [],\n        \"train_class_loss\": [],\n        \"train_center_loss\": [],\n        \"train_acc\": [],\n        \"val_class_loss\": [],\n        \"val_center_loss\": [],\n        \"val_acc\": []\n    }\n\n    @tf.function\n    def train_step(inputs, labels):\n        with tf.GradientTape() as tape:\n            logits, center_loss = model([inputs, labels], training=True)\n            classification_loss = tf.keras.losses.CategoricalCrossentropy()(labels, logits)\n            total_loss = classification_loss + center_loss_weight * center_loss\n\n        gradients = tape.gradient(total_loss, model.trainable_variables)\n        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n\n        predictions = tf.argmax(logits, axis=-1)\n        labels_true = tf.argmax(labels, axis=-1)\n        train_acc = tf.reduce_mean(tf.cast(tf.equal(predictions, labels_true), tf.float32))\n\n        return total_loss, classification_loss, center_loss, train_acc\n\n    @tf.function\n    def eval_step(inputs, labels):\n        logits, center_loss = model([inputs, labels], training=False)\n        classification_loss = tf.keras.losses.CategoricalCrossentropy()(labels, logits)\n\n        predictions = tf.argmax(logits, axis=-1)\n        labels_true = tf.argmax(labels, axis=-1)\n        accuracy = tf.reduce_mean(tf.cast(tf.equal(predictions, labels_true), tf.float32))\n\n        return classification_loss, center_loss, accuracy\n\n    for epoch in range(epochs):\n        print(f\"Epoch {epoch+1}/{epochs}\")\n\n        # Training loop\n        epoch_loss, epoch_class_loss, epoch_center_loss, epoch_acc = 0, 0, 0, 0\n        for step in range(steps_per_epoch):\n            inputs_batch, labels_batch = next(train_generator)\n            loss, class_loss, center_loss, acc = train_step(inputs_batch, labels_batch)\n            epoch_loss += loss\n            epoch_class_loss += class_loss\n            epoch_center_loss += center_loss\n            epoch_acc += acc\n\n        epoch_loss /= steps_per_epoch\n        epoch_class_loss /= steps_per_epoch\n        epoch_center_loss /= steps_per_epoch\n        epoch_acc /= steps_per_epoch\n\n        print(f\"Train Loss: {epoch_loss:.4f}, Class Loss: {epoch_class_loss:.4f}, Center Loss: {epoch_center_loss:.4f}, Acc: {epoch_acc:.4f}\")\n\n        history[\"train_loss\"].append(epoch_loss)\n        history[\"train_class_loss\"].append(epoch_class_loss)\n        history[\"train_center_loss\"].append(epoch_center_loss)\n        history[\"train_acc\"].append(epoch_acc)\n\n        # Validation loop\n        val_class_loss, val_center_loss, val_acc = 0, 0, 0\n        for step in range(validation_steps):\n            inputs_batch, labels_batch = next(val_generator)\n            class_loss, center_loss, acc = eval_step(inputs_batch, labels_batch)\n            val_class_loss += class_loss\n            val_center_loss += center_loss\n            val_acc += acc\n\n        val_class_loss /= validation_steps\n        val_center_loss /= validation_steps\n        val_acc /= validation_steps\n\n        print(f\"Val Class Loss: {val_class_loss:.4f}, Val Center Loss: {val_center_loss:.4f}, Val Acc: {val_acc:.4f}\")\n\n        history[\"val_class_loss\"].append(val_class_loss)\n        history[\"val_center_loss\"].append(val_center_loss)\n        history[\"val_acc\"].append(val_acc)\n\n    return history\n\n# Initialize ImageDataGenerator with augmentation options (without rescaling)\ntrain_datagen = ImageDataGenerator(\n    rotation_range=20,           # Randomly rotate images by 20 degrees\n    width_shift_range=0.2,       # Randomly shift images horizontally\n    height_shift_range=0.2,      # Randomly shift images vertically\n    shear_range=0.2,             # Shear transformation\n    zoom_range=0.2,              # Zoom in/out\n    horizontal_flip=True,        # Random horizontal flipping\n    fill_mode='nearest'          # Filling pixels after transformations\n)\n\n# Example usage with specified values\ninput_shape = (224, 224, 3)        # Input shape for images (224x224 RGB)\nnum_classes = 31                   # Number of classes in the dataset\nembedding_dim = 768              # Dimensionality of the embedding space\ndropout_rate = 0.1               # Dropout rate for regularization\nweight_decay = 0.05 #0.005            # L2 regularization weight\ncenter_loss_weight = 0.01 #0.0001          # Weight for center loss\nlearning_rate = 1e-4               # Learning rate for the optimizer\nbatch_size = 32                    # Batch size for training\nepochs = 30                      # Number of epochs to train\n\nval_datagen = ImageDataGenerator()  # No additional augmentations for validation\n\n# Load and augment training data\ntrain_generator = train_datagen.flow(X_train, y_train, batch_size=batch_size)\n\n# Load validation data\nval_generator = val_datagen.flow(X_val, y_val, batch_size=batch_size)\n\nsteps_per_epoch = len(X_train) // batch_size\nvalidation_steps = len(X_val)  // batch_size\n\n# Build the model using VGG19 and center loss\nembedding_model, full_model = build_vgg19_kde_loss(input_shape, num_classes, embedding_dim, dropout_rate, weight_decay)\n# Train the model using data generators\nhistory = train_and_evaluate(full_model, train_generator, val_generator, steps_per_epoch, validation_steps, epochs, center_loss_weight, learning_rate)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-24T00:57:27.264954Z","iopub.execute_input":"2024-09-24T00:57:27.265359Z","iopub.status.idle":"2024-09-24T01:14:25.394775Z","shell.execute_reply.started":"2024-09-24T00:57:27.265323Z","shell.execute_reply":"2024-09-24T01:14:25.393828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = train_and_evaluate(full_model, train_generator, val_generator, steps_per_epoch, validation_steps, epochs, center_loss_weight, learning_rate)","metadata":{"execution":{"iopub.status.busy":"2024-09-24T01:15:35.870930Z","iopub.execute_input":"2024-09-24T01:15:35.871941Z","iopub.status.idle":"2024-09-24T01:32:20.282237Z","shell.execute_reply.started":"2024-09-24T01:15:35.871897Z","shell.execute_reply":"2024-09-24T01:32:20.281267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.manifold import TSNE\nfrom sklearn.preprocessing import LabelEncoder\nfrom matplotlib import cm\nfrom matplotlib.colors import ListedColormap\n\n\n#embedding_model = models.Model(inputs=model.inputs[0], outputs=model.get_layer('embeddings').output)\n\n# Generate embeddings with 'training=False'\nembeddings = embedding_model.predict(images_np_preprocessed)\n\n# Sample image embeddings and labels\n# image_embeddings = ... (your embeddings)\n# labels_np = ... (your string labels)\n\n# Convert string labels to numeric labels\nlabel_encoder = LabelEncoder()\nnumeric_labels = label_encoder.fit_transform(labels_np)\n\n# Use t-SNE to reduce the embedding space to 2D for visualization\ntsne = TSNE(n_components=2, random_state=42)\nembeddings_2d = tsne.fit_transform(embeddings)  # Use your actual embeddings here\n\n# Create a custom color map to support 31 classes\ncolors = cm.get_cmap('tab20b', 31)  # 'tab20b' offers a distinct palette; we can define 31 colors explicitly\n\n# Plot the 2D embeddings with color based on numeric labels\nplt.figure(figsize=(10, 10))\nscatter = plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], \n                      c=numeric_labels, cmap=colors, s=20)  # Decreased marker size (s=20)\n\n# Add a color legend\nlegend1 = plt.legend(*scatter.legend_elements(), title=\"Person\")\nplt.gca().add_artist(legend1)\n\n# Set plot details\nplt.title('t-SNE of Image Embeddings (Color-coded)')\nplt.xlabel('Component 1')\nplt.ylabel('Component 2')\n\n# Show the plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-09-24T01:33:20.488106Z","iopub.execute_input":"2024-09-24T01:33:20.488943Z","iopub.status.idle":"2024-09-24T01:33:48.233273Z","shell.execute_reply.started":"2024-09-24T01:33:20.488903Z","shell.execute_reply":"2024-09-24T01:33:48.232352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# KDE + Inter-Class","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers, models, regularizers\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models, regularizers\nimport numpy as np\n\nclass KDELossLayer(tf.keras.layers.Layer):\n    def __init__(self, bandwidth=1.0, margin=2.0, **kwargs):\n        super(KDELossLayer, self).__init__(**kwargs)\n        self.bandwidth = tf.cast(bandwidth, tf.float32)\n        self.margin = tf.cast(margin, tf.float32)\n\n    def call(self, inputs):\n        embeddings, labels = inputs\n\n        # Ensure embeddings are float32\n        embeddings = tf.cast(embeddings, tf.float32)\n\n        # Convert labels to one-hot encoding\n        labels = tf.argmax(labels, axis=-1, output_type=tf.int32)\n        one_hot_labels = tf.one_hot(labels, depth=tf.reduce_max(labels) + 1)\n\n        # Compute pairwise distances for all embeddings\n        pairwise_dists = tf.norm(\n            tf.expand_dims(embeddings, 1) - tf.expand_dims(embeddings, 0), axis=-1\n        )\n\n        # Gaussian kernel for all distances (intra-class density)\n        kde_density = tf.exp(-pairwise_dists**2 / (2 * self.bandwidth**2))\n\n        # For each class, apply the mask to isolate class members (intra-class mask)\n        mask = tf.matmul(one_hot_labels, tf.transpose(one_hot_labels))\n        \n        # Avoid self-contribution by masking out diagonal elements\n        mask_off_diagonal = tf.linalg.set_diag(mask, tf.zeros(tf.shape(mask)[0]))\n\n        # Compute KDE loss for each class (intra-class KDE)\n        kde_class_density = tf.reduce_sum(kde_density * mask_off_diagonal, axis=-1)\n\n        # Intra-class KDE loss\n        kde_loss = -tf.reduce_mean(tf.math.log(kde_class_density + 1e-8))\n        \n        # Add margin-based inter-class separation\n        # Create inter-class mask (1 - mask), where classes are different\n        inter_class_mask = 1.0 - mask\n        \n        # Compute distances for inter-class pairs only\n        inter_class_dists = pairwise_dists * inter_class_mask\n        \n        # Penalize distances that are smaller than the margin\n        # Penalty term for inter-class distances smaller than the margin\n        margin_penalty = tf.maximum(0.0, self.margin - inter_class_dists)\n\n        # Inter-class loss is the mean of the margin penalties\n        inter_class_loss = tf.reduce_mean(margin_penalty)\n\n        # Total loss: Intra-class (KDE loss) + Inter-class (Margin loss)\n        total_loss = kde_loss + inter_class_loss\n\n        return total_loss\n\ndef build_vgg19_kde_loss(input_shape, num_classes, embedding_dim, dropout_rate, weight_decay):\n    # Define input layers\n    inputs = layers.Input(shape=input_shape, name='input')\n    labels_input = layers.Input(shape=(num_classes,), name='labels_input', dtype='float32')\n\n    # Define VGG19 backbone (without the top layers)\n    base_model = tf.keras.applications.VGG19(include_top=False, input_shape=input_shape, weights='imagenet')\n\n    for layer in base_model.layers[:15]:  # Freeze the first 15 layers (you can adjust this number)\n        layer.trainable = False\n    \n    # Flatten the output of the VGG19 backbone\n    x = base_model.output\n    x = layers.Flatten()(x)\n    \n    x = layers.Dense(1231, activation='swish', kernel_regularizer=regularizers.l2(weight_decay), bias_regularizer=regularizers.l2(0.01))(x)\n    x = layers.Dropout(dropout_rate)(x)\n    x = layers.Dense(300, activation='swish', kernel_regularizer=regularizers.l2(weight_decay), bias_regularizer=regularizers.l2(0.01))(x)\n    x = layers.Dropout(dropout_rate)(x)\n    x = layers.Dense(75, activation='swish', kernel_regularizer=regularizers.l2(weight_decay), bias_regularizer=regularizers.l2(0.01))(x)\n    x = layers.Dropout(dropout_rate)(x)\n    x = layers.Dense(1003, activation='swish', kernel_regularizer=regularizers.l2(weight_decay), bias_regularizer=regularizers.l2(0.01))(x)\n    x = layers.Dense(embedding_dim, activation='swish')(x)\n\n    # Define the embedding model\n    embedding_model = models.Model(inputs=base_model.input, outputs=x, name='embedding_model')\n\n    # Generate embeddings for the inputs\n    embedding = embedding_model(inputs)\n\n    # Define logits for classification using the embedding\n    logits = layers.Dense(num_classes, activation='softmax', name='classification_layer')(embedding)\n\n    # Define the custom KDE loss layer\n    kde_loss_layer = KDELossLayer()\n    kde_loss_output = kde_loss_layer([embedding, labels_input])\n\n    # Define the full model with classification and KDE loss\n    full_model = models.Model(\n        inputs=[inputs, labels_input],\n        outputs=[logits, kde_loss_output],\n        name='full_model'\n    )\n\n    return embedding_model, full_model\n\ndef train_and_evaluate(model, train_generator, val_generator, steps_per_epoch, validation_steps, epochs, center_loss_weight, learning_rate):\n    optimizer = tf.keras.optimizers.RMSprop(learning_rate)\n\n    history = {\n        \"train_loss\": [],\n        \"train_class_loss\": [],\n        \"train_center_loss\": [],\n        \"train_acc\": [],\n        \"val_class_loss\": [],\n        \"val_center_loss\": [],\n        \"val_acc\": []\n    }\n\n    @tf.function\n    def train_step(inputs, labels):\n        with tf.GradientTape() as tape:\n            logits, center_loss = model([inputs, labels], training=True)\n            classification_loss = tf.keras.losses.CategoricalCrossentropy()(labels, logits)\n            total_loss = classification_loss + center_loss_weight * center_loss\n\n        gradients = tape.gradient(total_loss, model.trainable_variables)\n        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n\n        predictions = tf.argmax(logits, axis=-1)\n        labels_true = tf.argmax(labels, axis=-1)\n        train_acc = tf.reduce_mean(tf.cast(tf.equal(predictions, labels_true), tf.float32))\n\n        return total_loss, classification_loss, center_loss, train_acc\n\n    @tf.function\n    def eval_step(inputs, labels):\n        logits, center_loss = model([inputs, labels], training=False)\n        classification_loss = tf.keras.losses.CategoricalCrossentropy()(labels, logits)\n\n        predictions = tf.argmax(logits, axis=-1)\n        labels_true = tf.argmax(labels, axis=-1)\n        accuracy = tf.reduce_mean(tf.cast(tf.equal(predictions, labels_true), tf.float32))\n\n        return classification_loss, center_loss, accuracy\n\n    for epoch in range(epochs):\n        print(f\"Epoch {epoch+1}/{epochs}\")\n\n        # Training loop\n        epoch_loss, epoch_class_loss, epoch_center_loss, epoch_acc = 0, 0, 0, 0\n        for step in range(steps_per_epoch):\n            inputs_batch, labels_batch = next(train_generator)\n            loss, class_loss, center_loss, acc = train_step(inputs_batch, labels_batch)\n            epoch_loss += loss\n            epoch_class_loss += class_loss\n            epoch_center_loss += center_loss\n            epoch_acc += acc\n\n        epoch_loss /= steps_per_epoch\n        epoch_class_loss /= steps_per_epoch\n        epoch_center_loss /= steps_per_epoch\n        epoch_acc /= steps_per_epoch\n\n        print(f\"Train Loss: {epoch_loss:.4f}, Class Loss: {epoch_class_loss:.4f}, Center Loss: {epoch_center_loss:.4f}, Acc: {epoch_acc:.4f}\")\n\n        history[\"train_loss\"].append(epoch_loss)\n        history[\"train_class_loss\"].append(epoch_class_loss)\n        history[\"train_center_loss\"].append(epoch_center_loss)\n        history[\"train_acc\"].append(epoch_acc)\n\n        # Validation loop\n        val_class_loss, val_center_loss, val_acc = 0, 0, 0\n        for step in range(validation_steps):\n            inputs_batch, labels_batch = next(val_generator)\n            class_loss, center_loss, acc = eval_step(inputs_batch, labels_batch)\n            val_class_loss += class_loss\n            val_center_loss += center_loss\n            val_acc += acc\n\n        val_class_loss /= validation_steps\n        val_center_loss /= validation_steps\n        val_acc /= validation_steps\n\n        print(f\"Val Class Loss: {val_class_loss:.4f}, Val Center Loss: {val_center_loss:.4f}, Val Acc: {val_acc:.4f}\")\n\n        history[\"val_class_loss\"].append(val_class_loss)\n        history[\"val_center_loss\"].append(val_center_loss)\n        history[\"val_acc\"].append(val_acc)\n\n    return history\n\n# Initialize ImageDataGenerator with augmentation options (without rescaling)\ntrain_datagen = ImageDataGenerator(\n    rotation_range=20,           # Randomly rotate images by 20 degrees\n    width_shift_range=0.2,       # Randomly shift images horizontally\n    height_shift_range=0.2,      # Randomly shift images vertically\n    shear_range=0.2,             # Shear transformation\n    zoom_range=0.2,              # Zoom in/out\n    horizontal_flip=True,        # Random horizontal flipping\n    fill_mode='nearest'          # Filling pixels after transformations\n)\n\n# Example usage with specified values\ninput_shape = (224, 224, 3)        # Input shape for images (224x224 RGB)\nnum_classes = 31                   # Number of classes in the dataset\nembedding_dim = 768              # Dimensionality of the embedding space\ndropout_rate = 0.1               # Dropout rate for regularization\nweight_decay = 0.05 #0.005            # L2 regularization weight\ncenter_loss_weight = 0.1 #0.0001          # Weight for center loss\nlearning_rate = 1e-4               # Learning rate for the optimizer\nbatch_size = 32                    # Batch size for training\nepochs = 75                      # Number of epochs to train\n\nval_datagen = ImageDataGenerator()  # No additional augmentations for validation\n\n# Load and augment training data\ntrain_generator = train_datagen.flow(X_train, y_train, batch_size=batch_size)\n\n# Load validation data\nval_generator = val_datagen.flow(X_val, y_val, batch_size=batch_size)\n\nsteps_per_epoch = len(X_train) // batch_size\nvalidation_steps = len(X_val)  // batch_size\n\n# Build the model using VGG19 and center loss\nembedding_model, full_model = build_vgg19_kde_loss(input_shape, num_classes, embedding_dim, dropout_rate, weight_decay)\n# Train the model using data generators\nhistory = train_and_evaluate(full_model, train_generator, val_generator, steps_per_epoch, validation_steps, epochs, center_loss_weight, learning_rate)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-24T02:38:29.475693Z","iopub.execute_input":"2024-09-24T02:38:29.476077Z","iopub.status.idle":"2024-09-24T03:20:10.973449Z","shell.execute_reply.started":"2024-09-24T02:38:29.476041Z","shell.execute_reply":"2024-09-24T03:20:10.972478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.manifold import TSNE\nfrom sklearn.preprocessing import LabelEncoder\nfrom matplotlib import cm\nfrom matplotlib.colors import ListedColormap\n\n\n#embedding_model = models.Model(inputs=model.inputs[0], outputs=model.get_layer('embeddings').output)\n\n# Generate embeddings with 'training=False'\nembeddings = embedding_model.predict(images_np_preprocessed)\n\n# Sample image embeddings and labels\n# image_embeddings = ... (your embeddings)\n# labels_np = ... (your string labels)\n\n# Convert string labels to numeric labels\nlabel_encoder = LabelEncoder()\nnumeric_labels = label_encoder.fit_transform(labels_np)\n\n# Use t-SNE to reduce the embedding space to 2D for visualization\ntsne = TSNE(n_components=2, random_state=42)\nembeddings_2d = tsne.fit_transform(embeddings)  # Use your actual embeddings here\n\n# Create a custom color map to support 31 classes\n = cm.get_cmap('tab20b', 31)  # 'tab20b' offers a distinct palette; we can define 31 colors explicitly\n\n# Plot the 2D embeddings with color based on numeric labels\nplt.figure(figsize=(10, 10))\nscatter = plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], \n                      c=numeric_labels, cmap=colors, s=20)  # Decreased marker size (s=20)\n\n# Add a color legend\nlegend1 = plt.legend(*scatter.legend_elements(), title=\"Person\")\nplt.gca().add_artist(legend1)\n\n# Set plot details\nplt.title('t-SNE of Image Embeddings (Color-coded)')\nplt.xlabel('Component 1')\nplt.ylabel('Component 2')\n\n# Show the plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-09-24T03:21:51.622432Z","iopub.execute_input":"2024-09-24T03:21:51.622830Z","iopub.status.idle":"2024-09-24T03:22:20.216143Z","shell.execute_reply.started":"2024-09-24T03:21:51.622790Z","shell.execute_reply":"2024-09-24T03:22:20.215143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# KDE + inter-class + k-means ","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers, models, regularizers\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models, regularizers\nimport numpy as np\n\nimport tensorflow as tf\nfrom sklearn.cluster import KMeans\ntf.config.run_functions_eagerly(True) \n\nclass KDELossLayer(tf.keras.layers.Layer):\n    def __init__(self, bandwidth=1.0, margin=2.0, num_subclusters=3, variance_threshold=0.5, **kwargs):\n        super(KDELossLayer, self).__init__(**kwargs)\n        self.bandwidth = tf.cast(bandwidth, tf.float32)\n        self.margin = tf.cast(margin, tf.float32)\n        self.num_subclusters = num_subclusters  # Number of sub-clusters for each class\n        self.variance_threshold = tf.cast(variance_threshold, tf.float32)\n\n    def call(self, inputs):\n        embeddings, labels = inputs\n\n        # Ensure embeddings are float32\n        embeddings = tf.cast(embeddings, tf.float32)\n\n        # Convert labels to one-hot encoding and integer labels\n        labels = tf.argmax(labels, axis=-1, output_type=tf.int32)\n        one_hot_labels = tf.one_hot(labels, depth=tf.reduce_max(labels) + 1)\n\n        # Compute pairwise distances for all embeddings\n        pairwise_dists = tf.norm(\n            tf.expand_dims(embeddings, 1) - tf.expand_dims(embeddings, 0), axis=-1\n        )\n\n        # Gaussian kernel for all distances (intra-class density)\n        kde_density = tf.exp(-pairwise_dists**2 / (2 * self.bandwidth**2))\n\n        # For each class, apply the mask to isolate class members (intra-class mask)\n        mask = tf.matmul(one_hot_labels, tf.transpose(one_hot_labels))\n\n        # Avoid self-contribution by masking out diagonal elements\n        mask_off_diagonal = tf.linalg.set_diag(mask, tf.zeros(tf.shape(mask)[0]))\n\n        # Compute KDE loss for each class (intra-class KDE)\n        kde_class_density = tf.reduce_sum(kde_density * mask_off_diagonal, axis=-1)\n\n        # Intra-class KDE loss\n        kde_loss = -tf.reduce_mean(tf.math.log(kde_class_density + 1e-8))\n\n        # Use map_fn to apply K-means clustering and variance penalty computation per class\n        unique_labels = tf.range(tf.reduce_max(labels) + 1)  # Get all class labels (0, 1, ..., num_classes-1)\n\n        def compute_cluster_penalty(class_label):\n            class_mask = tf.equal(labels, class_label)\n            class_embeddings = tf.boolean_mask(embeddings, class_mask)\n\n            # Perform K-means clustering on the embeddings of this class\n            if tf.shape(class_embeddings)[0] > self.num_subclusters:  # Ensure enough points for clustering\n                # Temporarily convert to numpy for KMeans since TensorFlow doesn't support KMeans directly\n                class_embeddings_np = class_embeddings.numpy()  # Convert to numpy temporarily for clustering\n                kmeans = KMeans(n_clusters=self.num_subclusters, n_init=10, random_state=42)\n                kmeans.fit(class_embeddings_np)  # Run K-means on the embeddings\n                \n                centroids = tf.constant(kmeans.cluster_centers_, dtype=tf.float32)\n                assignments = kmeans.labels_\n\n                # Compute variance for each sub-cluster\n                variance_penalty = 0.0\n                for i in range(self.num_subclusters):\n                    cluster_points = tf.boolean_mask(class_embeddings, assignments == i)\n                    centroid = centroids[i]\n\n                    # Variance: Mean squared distance to the centroid\n                    variance = tf.reduce_mean(tf.square(cluster_points - centroid))\n\n                    # Apply variance penalty if it exceeds the threshold\n                    if variance > self.variance_threshold:\n                        variance_penalty += variance - self.variance_threshold\n\n                return variance_penalty\n            return 0.0\n\n        # Compute total variance penalty across all unique labels\n        total_variance_penalty = tf.reduce_sum(tf.map_fn(compute_cluster_penalty, unique_labels, dtype=tf.float32))\n\n        # Add margin-based inter-class separation\n        inter_class_mask = 1.0 - mask  # Inter-class mask (where classes are different)\n        inter_class_dists = pairwise_dists * inter_class_mask\n        margin_penalty = tf.maximum(0.0, self.margin - inter_class_dists)  # Penalty for distances below margin\n        inter_class_loss = tf.reduce_mean(margin_penalty)\n\n        # Total loss: Intra-class (KDE loss) + Inter-class (Margin loss) + Variance penalty\n        total_loss = kde_loss + inter_class_loss + total_variance_penalty\n\n        return total_loss\n\n    def compute_output_shape(self, input_shape):\n        return (input_shape[0][0], 1)\n\ndef build_vgg19_kde_loss(input_shape, num_classes, embedding_dim, dropout_rate, weight_decay):\n    # Define input layers\n    inputs = layers.Input(shape=input_shape, name='input')\n    labels_input = layers.Input(shape=(num_classes,), name='labels_input', dtype='float32')\n\n    # Define VGG19 backbone (without the top layers)\n    base_model = tf.keras.applications.VGG19(include_top=False, input_shape=input_shape, weights='imagenet')\n\n    for layer in base_model.layers[:15]:  # Freeze the first 15 layers (you can adjust this number)\n        layer.trainable = False\n    \n    # Flatten the output of the VGG19 backbone\n    x = base_model.output\n    x = layers.Flatten()(x)\n    \n    x = layers.Dense(1231, activation='swish', kernel_regularizer=regularizers.l2(weight_decay), bias_regularizer=regularizers.l2(0.01))(x)\n    x = layers.Dropout(dropout_rate)(x)\n    x = layers.Dense(300, activation='swish', kernel_regularizer=regularizers.l2(weight_decay), bias_regularizer=regularizers.l2(0.01))(x)\n    x = layers.Dropout(dropout_rate)(x)\n    x = layers.Dense(75, activation='swish', kernel_regularizer=regularizers.l2(weight_decay), bias_regularizer=regularizers.l2(0.01))(x)\n    x = layers.Dropout(dropout_rate)(x)\n    x = layers.Dense(1003, activation='swish', kernel_regularizer=regularizers.l2(weight_decay), bias_regularizer=regularizers.l2(0.01))(x)\n    x = layers.Dense(embedding_dim, activation='swish')(x)\n\n    # Define the embedding model\n    embedding_model = models.Model(inputs=base_model.input, outputs=x, name='embedding_model')\n\n    # Generate embeddings for the inputs\n    embedding = embedding_model(inputs)\n\n    # Define logits for classification using the embedding\n    logits = layers.Dense(num_classes, activation='softmax', name='classification_layer')(embedding)\n\n    # Define the custom KDE loss layer\n    kde_loss_layer = KDELossLayer()\n    kde_loss_output = kde_loss_layer([embedding, labels_input])\n\n    # Define the full model with classification and KDE loss\n    full_model = models.Model(\n        inputs=[inputs, labels_input],\n        outputs=[logits, kde_loss_output],\n        name='full_model'\n    )\n\n    return embedding_model, full_model\n\ndef train_and_evaluate(model, train_generator, val_generator, steps_per_epoch, validation_steps, epochs, center_loss_weight, learning_rate):\n    optimizer = tf.keras.optimizers.RMSprop(learning_rate)\n\n    history = {\n        \"train_loss\": [],\n        \"train_class_loss\": [],\n        \"train_center_loss\": [],\n        \"train_acc\": [],\n        \"val_class_loss\": [],\n        \"val_center_loss\": [],\n        \"val_acc\": []\n    }\n\n    @tf.function\n    def train_step(inputs, labels):\n        with tf.GradientTape() as tape:\n            logits, center_loss = model([inputs, labels], training=True)\n            classification_loss = tf.keras.losses.CategoricalCrossentropy()(labels, logits)\n            total_loss = classification_loss + center_loss_weight * center_loss\n\n        gradients = tape.gradient(total_loss, model.trainable_variables)\n        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n\n        predictions = tf.argmax(logits, axis=-1)\n        labels_true = tf.argmax(labels, axis=-1)\n        train_acc = tf.reduce_mean(tf.cast(tf.equal(predictions, labels_true), tf.float32))\n\n        return total_loss, classification_loss, center_loss, train_acc\n\n    @tf.function\n    def eval_step(inputs, labels):\n        logits, center_loss = model([inputs, labels], training=False)\n        classification_loss = tf.keras.losses.CategoricalCrossentropy()(labels, logits)\n\n        predictions = tf.argmax(logits, axis=-1)\n        labels_true = tf.argmax(labels, axis=-1)\n        accuracy = tf.reduce_mean(tf.cast(tf.equal(predictions, labels_true), tf.float32))\n\n        return classification_loss, center_loss, accuracy\n\n    for epoch in range(epochs):\n        print(f\"Epoch {epoch+1}/{epochs}\")\n\n        # Training loop\n        epoch_loss, epoch_class_loss, epoch_center_loss, epoch_acc = 0, 0, 0, 0\n        for step in range(steps_per_epoch):\n            inputs_batch, labels_batch = next(train_generator)\n            loss, class_loss, center_loss, acc = train_step(inputs_batch, labels_batch)\n            epoch_loss += loss\n            epoch_class_loss += class_loss\n            epoch_center_loss += center_loss\n            epoch_acc += acc\n\n        epoch_loss /= steps_per_epoch\n        epoch_class_loss /= steps_per_epoch\n        epoch_center_loss /= steps_per_epoch\n        epoch_acc /= steps_per_epoch\n\n        print(f\"Train Loss: {epoch_loss:.4f}, Class Loss: {epoch_class_loss:.4f}, Center Loss: {epoch_center_loss:.4f}, Acc: {epoch_acc:.4f}\")\n\n        history[\"train_loss\"].append(epoch_loss)\n        history[\"train_class_loss\"].append(epoch_class_loss)\n        history[\"train_center_loss\"].append(epoch_center_loss)\n        history[\"train_acc\"].append(epoch_acc)\n\n        # Validation loop\n        val_class_loss, val_center_loss, val_acc = 0, 0, 0\n        for step in range(validation_steps):\n            inputs_batch, labels_batch = next(val_generator)\n            class_loss, center_loss, acc = eval_step(inputs_batch, labels_batch)\n            val_class_loss += class_loss\n            val_center_loss += center_loss\n            val_acc += acc\n\n        val_class_loss /= validation_steps\n        val_center_loss /= validation_steps\n        val_acc /= validation_steps\n\n        print(f\"Val Class Loss: {val_class_loss:.4f}, Val Center Loss: {val_center_loss:.4f}, Val Acc: {val_acc:.4f}\")\n\n        history[\"val_class_loss\"].append(val_class_loss)\n        history[\"val_center_loss\"].append(val_center_loss)\n        history[\"val_acc\"].append(val_acc)\n\n    return history\n\n# Initialize ImageDataGenerator with augmentation options (without rescaling)\ntrain_datagen = ImageDataGenerator(\n    rotation_range=20,           # Randomly rotate images by 20 degrees\n    width_shift_range=0.2,       # Randomly shift images horizontally\n    height_shift_range=0.2,      # Randomly shift images vertically\n    shear_range=0.2,             # Shear transformation\n    zoom_range=0.2,              # Zoom in/out\n    horizontal_flip=True,        # Random horizontal flipping\n    fill_mode='nearest'          # Filling pixels after transformations\n)\n\n# Example usage with specified values\ninput_shape = (224, 224, 3)        # Input shape for images (224x224 RGB)\nnum_classes = 31                   # Number of classes in the dataset\nembedding_dim = 768              # Dimensionality of the embedding space\ndropout_rate = 0.1               # Dropout rate for regularization\nweight_decay = 0.05 #0.005            # L2 regularization weight\ncenter_loss_weight = 0.1 #0.0001          # Weight for center loss\nlearning_rate = 1e-4               # Learning rate for the optimizer\nbatch_size = 32                    # Batch size for training\nepochs = 75                      # Number of epochs to train\n\nval_datagen = ImageDataGenerator()  # No additional augmentations for validation\n\n# Load and augment training data\ntrain_generator = train_datagen.flow(X_train, y_train, batch_size=batch_size)\n\n# Load validation data\nval_generator = val_datagen.flow(X_val, y_val, batch_size=batch_size)\n\nsteps_per_epoch = len(X_train) // batch_size\nvalidation_steps = len(X_val)  // batch_size\n\n# Build the model using VGG19 and center loss\nembedding_model, full_model = build_vgg19_kde_loss(input_shape, num_classes, embedding_dim, dropout_rate, weight_decay)\n# Train the model using data generators\nhistory = train_and_evaluate(full_model, train_generator, val_generator, steps_per_epoch, validation_steps, epochs, center_loss_weight, learning_rate)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-24T13:05:10.464543Z","iopub.execute_input":"2024-09-24T13:05:10.465235Z","iopub.status.idle":"2024-09-24T14:12:24.142136Z","shell.execute_reply.started":"2024-09-24T13:05:10.465180Z","shell.execute_reply":"2024-09-24T14:12:24.140059Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Epoch 1/75\nTrain Loss: 4.1826, Class Loss: 3.4206, Center Loss: 7.6202, Acc: 0.0374\nVal Class Loss: 3.3328, Val Center Loss: 7.7954, Val Acc: 0.0990\nEpoch 2/75\nTrain Loss: 4.0229, Class Loss: 3.1696, Center Loss: 8.5330, Acc: 0.0921\nVal Class Loss: 2.8831, Val Center Loss: 7.0346, Val Acc: 0.0964\nEpoch 3/75\nTrain Loss: 3.7291, Class Loss: 2.8714, Center Loss: 8.5768, Acc: 0.1417\nVal Class Loss: 2.6932, Val Center Loss: 8.1163, Val Acc: 0.2188\nEpoch 4/75\nTrain Loss: 3.4908, Class Loss: 2.6160, Center Loss: 8.7476, Acc: 0.2003\nVal Class Loss: 2.5073, Val Center Loss: 8.0317, Val Acc: 0.1927\nEpoch 5/75\nTrain Loss: 3.3516, Class Loss: 2.4535, Center Loss: 8.9808, Acc: 0.2383\nVal Class Loss: 2.2776, Val Center Loss: 6.8506, Val Acc: 0.3099\nEpoch 6/75\nTrain Loss: 3.1679, Class Loss: 2.2828, Center Loss: 8.8512, Acc: 0.2723\nVal Class Loss: 2.3449, Val Center Loss: 8.0243, Val Acc: 0.2370\nEpoch 7/75\nTrain Loss: 3.0248, Class Loss: 2.1298, Center Loss: 8.9496, Acc: 0.3103\nVal Class Loss: 1.9945, Val Center Loss: 8.0136, Val Acc: 0.3307\nEpoch 8/75\nTrain Loss: 2.9245, Class Loss: 1.9837, Center Loss: 9.4083, Acc: 0.3577\nVal Class Loss: 1.7731, Val Center Loss: 7.9941, Val Acc: 0.4115\nEpoch 9/75\nTrain Loss: 2.8275, Class Loss: 1.9105, Center Loss: 9.1704, Acc: 0.3733\nVal Class Loss: 1.7198, Val Center Loss: 8.4732, Val Acc: 0.4427\nEpoch 10/75\nTrain Loss: 2.6866, Class Loss: 1.7702, Center Loss: 9.1642, Acc: 0.4230\nVal Class Loss: 1.7320, Val Center Loss: 7.8870, Val Acc: 0.3828\nEpoch 11/75\nTrain Loss: 2.5630, Class Loss: 1.6368, Center Loss: 9.2613, Acc: 0.4581\nVal Class Loss: 1.5360, Val Center Loss: 7.8254, Val Acc: 0.4740\nEpoch 12/75\nTrain Loss: 2.4452, Class Loss: 1.5274, Center Loss: 9.1784, Acc: 0.5117\nVal Class Loss: 1.4374, Val Center Loss: 7.9371, Val Acc: 0.5417\nEpoch 13/75\nTrain Loss: 2.3459, Class Loss: 1.4343, Center Loss: 9.1167, Acc: 0.5346\nVal Class Loss: 1.2384, Val Center Loss: 7.9065, Val Acc: 0.5911\nEpoch 14/75\nTrain Loss: 2.1663, Class Loss: 1.2402, Center Loss: 9.2610, Acc: 0.5993\nVal Class Loss: 1.1143, Val Center Loss: 7.9496, Val Acc: 0.6380\nEpoch 15/75\nTrain Loss: 2.0700, Class Loss: 1.1123, Center Loss: 9.5769, Acc: 0.6468\nVal Class Loss: 1.1198, Val Center Loss: 8.0602, Val Acc: 0.6589\nEpoch 16/75\nTrain Loss: 1.9947, Class Loss: 1.0922, Center Loss: 9.0243, Acc: 0.6741\nVal Class Loss: 0.9126, Val Center Loss: 7.9281, Val Acc: 0.7214\nEpoch 17/75\nTrain Loss: 1.8329, Class Loss: 0.8777, Center Loss: 9.5516, Acc: 0.7377\nVal Class Loss: 0.8649, Val Center Loss: 8.2192, Val Acc: 0.7448\nEpoch 18/75\nTrain Loss: 1.6996, Class Loss: 0.8203, Center Loss: 8.7930, Acc: 0.7545\nVal Class Loss: 0.6648, Val Center Loss: 8.4658, Val Acc: 0.8125\nEpoch 19/75\nTrain Loss: 1.6264, Class Loss: 0.7303, Center Loss: 8.9608, Acc: 0.7852\nVal Class Loss: 0.7697, Val Center Loss: 8.6142, Val Acc: 0.7474\nEpoch 20/75\nTrain Loss: 1.5575, Class Loss: 0.6132, Center Loss: 9.4431, Acc: 0.8259\nVal Class Loss: 0.5134, Val Center Loss: 8.1129, Val Acc: 0.8542\nEpoch 21/75\nTrain Loss: 1.4777, Class Loss: 0.5508, Center Loss: 9.2686, Acc: 0.8426\nVal Class Loss: 0.4999, Val Center Loss: 7.6392, Val Acc: 0.8490\nEpoch 22/75\nTrain Loss: 1.3655, Class Loss: 0.4882, Center Loss: 8.7727, Acc: 0.8599\nVal Class Loss: 0.4592, Val Center Loss: 8.9488, Val Acc: 0.8568\nEpoch 23/75\nTrain Loss: 1.3450, Class Loss: 0.4448, Center Loss: 9.0017, Acc: 0.8800\nVal Class Loss: 0.4697, Val Center Loss: 8.0720, Val Acc: 0.8620\nEpoch 24/75\nTrain Loss: 1.2559, Class Loss: 0.3984, Center Loss: 8.5756, Acc: 0.8929\nVal Class Loss: 0.4108, Val Center Loss: 8.3826, Val Acc: 0.8698\nEpoch 25/75\nTrain Loss: 1.2115, Class Loss: 0.3561, Center Loss: 8.5536, Acc: 0.9163\nVal Class Loss: 0.3695, Val Center Loss: 7.2328, Val Acc: 0.8958\nEpoch 26/75\nTrain Loss: 1.1583, Class Loss: 0.2991, Center Loss: 8.5922, Acc: 0.9230\nVal Class Loss: 0.4566, Val Center Loss: 8.3288, Val Acc: 0.8568\nEpoch 27/75\nTrain Loss: 1.1319, Class Loss: 0.2831, Center Loss: 8.4884, Acc: 0.9252\nVal Class Loss: 0.4267, Val Center Loss: 7.8003, Val Acc: 0.8932\nEpoch 28/75\nTrain Loss: 1.1119, Class Loss: 0.2783, Center Loss: 8.3361, Acc: 0.9325\nVal Class Loss: 0.3620, Val Center Loss: 8.1617, Val Acc: 0.8906\nEpoch 29/75\nTrain Loss: 1.0851, Class Loss: 0.2388, Center Loss: 8.4635, Acc: 0.9386\nVal Class Loss: 0.4074, Val Center Loss: 7.5655, Val Acc: 0.8750\nEpoch 30/75\nTrain Loss: 1.0007, Class Loss: 0.2019, Center Loss: 7.9881, Acc: 0.9470\nVal Class Loss: 0.3431, Val Center Loss: 7.9837, Val Acc: 0.9010\nEpoch 31/75\nTrain Loss: 0.9943, Class Loss: 0.2018, Center Loss: 7.9258, Acc: 0.9526\nVal Class Loss: 0.5103, Val Center Loss: 8.6852, Val Acc: 0.8724\nEpoch 32/75\nTrain Loss: 1.0317, Class Loss: 0.1962, Center Loss: 8.3548, Acc: 0.9576\nVal Class Loss: 0.3473, Val Center Loss: 7.3728, Val Acc: 0.9089\nEpoch 33/75\nTrain Loss: 1.0193, Class Loss: 0.2091, Center Loss: 8.1020, Acc: 0.9503\nVal Class Loss: 0.3402, Val Center Loss: 7.9883, Val Acc: 0.8984\nEpoch 34/75\nTrain Loss: 1.0164, Class Loss: 0.2000, Center Loss: 8.1638, Acc: 0.9442\nVal Class Loss: 0.2341, Val Center Loss: 7.6835, Val Acc: 0.9427\nEpoch 35/75\nTrain Loss: 0.9448, Class Loss: 0.1215, Center Loss: 8.2328, Acc: 0.9743\nVal Class Loss: 0.2812, Val Center Loss: 7.6376, Val Acc: 0.9115\nEpoch 36/75\nTrain Loss: 0.9731, Class Loss: 0.1509, Center Loss: 8.2211, Acc: 0.9643\nVal Class Loss: 0.2393, Val Center Loss: 7.3531, Val Acc: 0.9245\nEpoch 37/75\nTrain Loss: 0.9683, Class Loss: 0.2052, Center Loss: 7.6310, Acc: 0.9515\nVal Class Loss: 0.2617, Val Center Loss: 7.6663, Val Acc: 0.9349\nEpoch 38/75\nTrain Loss: 0.8469, Class Loss: 0.0895, Center Loss: 7.5749, Acc: 0.9810\nVal Class Loss: 0.2516, Val Center Loss: 8.0185, Val Acc: 0.9245\nEpoch 39/75\nTrain Loss: 0.8642, Class Loss: 0.0971, Center Loss: 7.6705, Acc: 0.9788\nVal Class Loss: 0.2725, Val Center Loss: 7.6604, Val Acc: 0.9271\nEpoch 40/75\nTrain Loss: 0.8973, Class Loss: 0.1112, Center Loss: 7.8611, Acc: 0.9738\nVal Class Loss: 0.2553, Val Center Loss: 7.9162, Val Acc: 0.9349\nEpoch 41/75\nTrain Loss: 0.9152, Class Loss: 0.1031, Center Loss: 8.1210, Acc: 0.9738\nVal Class Loss: 0.2263, Val Center Loss: 7.8377, Val Acc: 0.9401\nEpoch 42/75\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[10], line 270\u001b[0m\n\u001b[1;32m    268\u001b[0m embedding_model, full_model \u001b[38;5;241m=\u001b[39m build_vgg19_kde_loss(input_shape, num_classes, embedding_dim, dropout_rate, weight_decay)\n\u001b[1;32m    269\u001b[0m \u001b[38;5;66;03m# Train the model using data generators\u001b[39;00m\n\u001b[0;32m--> 270\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcenter_loss_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[10], line 195\u001b[0m, in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(model, train_generator, val_generator, steps_per_epoch, validation_steps, epochs, center_loss_weight, learning_rate)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(steps_per_epoch):\n\u001b[1;32m    194\u001b[0m     inputs_batch, labels_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(train_generator)\n\u001b[0;32m--> 195\u001b[0m     loss, class_loss, center_loss, acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    196\u001b[0m     epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n\u001b[1;32m    197\u001b[0m     epoch_class_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m class_loss\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:810\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_functions_eagerly:\n\u001b[1;32m    809\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name, tf_function_call\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 810\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;66;03m# Only count the statistics the first time, before initialization took\u001b[39;00m\n\u001b[1;32m    813\u001b[0m \u001b[38;5;66;03m# place.\u001b[39;00m\n\u001b[1;32m    814\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","Cell \u001b[0;32mIn[10], line 164\u001b[0m, in \u001b[0;36mtrain_and_evaluate.<locals>.train_step\u001b[0;34m(inputs, labels)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;129m@tf\u001b[39m\u001b[38;5;241m.\u001b[39mfunction\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_step\u001b[39m(inputs, labels):\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[0;32m--> 164\u001b[0m         logits, center_loss \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m         classification_loss \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mCategoricalCrossentropy()(labels, logits)\n\u001b[1;32m    166\u001b[0m         total_loss \u001b[38;5;241m=\u001b[39m classification_loss \u001b[38;5;241m+\u001b[39m center_loss_weight \u001b[38;5;241m*\u001b[39m center_loss\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:846\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    844\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    845\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 846\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[38;5;66;03m# Change the layout for the layer output if needed.\u001b[39;00m\n\u001b[1;32m    848\u001b[0m \u001b[38;5;66;03m# This is useful for relayout intermediate tensor in the model\u001b[39;00m\n\u001b[1;32m    849\u001b[0m \u001b[38;5;66;03m# to achieve the optimal performance.\u001b[39;00m\n\u001b[1;32m    850\u001b[0m distribution \u001b[38;5;241m=\u001b[39m distribution_lib\u001b[38;5;241m.\u001b[39mdistribution()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/ops/operation.py:48\u001b[0m, in \u001b[0;36mOperation.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     43\u001b[0m             call_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall\n\u001b[1;32m     44\u001b[0m     call_fn \u001b[38;5;241m=\u001b[39m traceback_utils\u001b[38;5;241m.\u001b[39minject_argument_info_in_traceback(\n\u001b[1;32m     45\u001b[0m         call_fn,\n\u001b[1;32m     46\u001b[0m         object_name\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.call()\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     47\u001b[0m     )\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# Plain flow.\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m any_symbolic_tensors(args, kwargs):\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:156\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m bound_signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_keras_call_info_injected\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/models/functional.py:202\u001b[0m, in \u001b[0;36mFunctional.call\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    201\u001b[0m             x\u001b[38;5;241m.\u001b[39m_keras_mask \u001b[38;5;241m=\u001b[39m mask\n\u001b[0;32m--> 202\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_through_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperation_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43moperation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m unpack_singleton(outputs)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/ops/function.py:155\u001b[0m, in \u001b[0;36mFunction._run_through_graph\u001b[0;34m(self, inputs, operation_fn, call_fn)\u001b[0m\n\u001b[1;32m    153\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m call_fn(op, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 155\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;66;03m# Update tensor_dict.\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(node\u001b[38;5;241m.\u001b[39moutputs, tree\u001b[38;5;241m.\u001b[39mflatten(outputs)):\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/models/functional.py:592\u001b[0m, in \u001b[0;36moperation_fn.<locals>.call\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    586\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    587\u001b[0m     \u001b[38;5;28mhasattr\u001b[39m(operation, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_call_has_training_arg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    588\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m operation\u001b[38;5;241m.\u001b[39m_call_has_training_arg\n\u001b[1;32m    589\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m training \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    590\u001b[0m ):\n\u001b[1;32m    591\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m training\n\u001b[0;32m--> 592\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moperation\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:846\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    844\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    845\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 846\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[38;5;66;03m# Change the layout for the layer output if needed.\u001b[39;00m\n\u001b[1;32m    848\u001b[0m \u001b[38;5;66;03m# This is useful for relayout intermediate tensor in the model\u001b[39;00m\n\u001b[1;32m    849\u001b[0m \u001b[38;5;66;03m# to achieve the optimal performance.\u001b[39;00m\n\u001b[1;32m    850\u001b[0m distribution \u001b[38;5;241m=\u001b[39m distribution_lib\u001b[38;5;241m.\u001b[39mdistribution()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/ops/operation.py:48\u001b[0m, in \u001b[0;36mOperation.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     43\u001b[0m             call_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall\n\u001b[1;32m     44\u001b[0m     call_fn \u001b[38;5;241m=\u001b[39m traceback_utils\u001b[38;5;241m.\u001b[39minject_argument_info_in_traceback(\n\u001b[1;32m     45\u001b[0m         call_fn,\n\u001b[1;32m     46\u001b[0m         object_name\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.call()\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     47\u001b[0m     )\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# Plain flow.\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m any_symbolic_tensors(args, kwargs):\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:156\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m bound_signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_keras_call_info_injected\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/models/functional.py:202\u001b[0m, in \u001b[0;36mFunctional.call\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    201\u001b[0m             x\u001b[38;5;241m.\u001b[39m_keras_mask \u001b[38;5;241m=\u001b[39m mask\n\u001b[0;32m--> 202\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_through_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperation_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43moperation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m unpack_singleton(outputs)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/ops/function.py:155\u001b[0m, in \u001b[0;36mFunction._run_through_graph\u001b[0;34m(self, inputs, operation_fn, call_fn)\u001b[0m\n\u001b[1;32m    153\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m call_fn(op, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 155\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;66;03m# Update tensor_dict.\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(node\u001b[38;5;241m.\u001b[39moutputs, tree\u001b[38;5;241m.\u001b[39mflatten(outputs)):\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/models/functional.py:592\u001b[0m, in \u001b[0;36moperation_fn.<locals>.call\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    586\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    587\u001b[0m     \u001b[38;5;28mhasattr\u001b[39m(operation, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_call_has_training_arg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    588\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m operation\u001b[38;5;241m.\u001b[39m_call_has_training_arg\n\u001b[1;32m    589\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m training \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    590\u001b[0m ):\n\u001b[1;32m    591\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m training\n\u001b[0;32m--> 592\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moperation\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:846\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    844\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    845\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 846\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[38;5;66;03m# Change the layout for the layer output if needed.\u001b[39;00m\n\u001b[1;32m    848\u001b[0m \u001b[38;5;66;03m# This is useful for relayout intermediate tensor in the model\u001b[39;00m\n\u001b[1;32m    849\u001b[0m \u001b[38;5;66;03m# to achieve the optimal performance.\u001b[39;00m\n\u001b[1;32m    850\u001b[0m distribution \u001b[38;5;241m=\u001b[39m distribution_lib\u001b[38;5;241m.\u001b[39mdistribution()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/ops/operation.py:48\u001b[0m, in \u001b[0;36mOperation.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     43\u001b[0m             call_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall\n\u001b[1;32m     44\u001b[0m     call_fn \u001b[38;5;241m=\u001b[39m traceback_utils\u001b[38;5;241m.\u001b[39minject_argument_info_in_traceback(\n\u001b[1;32m     45\u001b[0m         call_fn,\n\u001b[1;32m     46\u001b[0m         object_name\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.call()\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     47\u001b[0m     )\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# Plain flow.\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m any_symbolic_tensors(args, kwargs):\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:156\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m bound_signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_keras_call_info_injected\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/layers/regularization/dropout.py:58\u001b[0m, in \u001b[0;36mDropout.call\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m training \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrate \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 58\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m            \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnoise_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnoise_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m            \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseed_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inputs\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/backend/tensorflow/random.py:78\u001b[0m, in \u001b[0;36mdropout\u001b[0;34m(inputs, rate, noise_shape, seed)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdropout\u001b[39m(inputs, rate, noise_shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 78\u001b[0m     seed \u001b[38;5;241m=\u001b[39m \u001b[43mtf_draw_seed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m     noise_shape \u001b[38;5;241m=\u001b[39m _get_concrete_noise_shape(inputs, noise_shape)\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mstateless_dropout(\n\u001b[1;32m     81\u001b[0m         inputs,\n\u001b[1;32m     82\u001b[0m         rate\u001b[38;5;241m=\u001b[39mrate,\n\u001b[1;32m     83\u001b[0m         noise_shape\u001b[38;5;241m=\u001b[39mnoise_shape,\n\u001b[1;32m     84\u001b[0m         seed\u001b[38;5;241m=\u001b[39mseed,\n\u001b[1;32m     85\u001b[0m     )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/backend/tensorflow/random.py:12\u001b[0m, in \u001b[0;36mtf_draw_seed\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtf_draw_seed\u001b[39m(seed):\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# TF ops only accept int32/64 seeds but our base seed is uint32.\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mcast(\u001b[43mdraw_seed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint32\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/random/seed_generator.py:138\u001b[0m, in \u001b[0;36mdraw_seed\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m convert_to_tensor\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(seed, SeedGenerator):\n\u001b[0;32m--> 138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mseed\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(seed, \u001b[38;5;28mint\u001b[39m):\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m convert_to_tensor([seed, \u001b[38;5;241m0\u001b[39m], dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muint32\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/random/seed_generator.py:88\u001b[0m, in \u001b[0;36mSeedGenerator.next\u001b[0;34m(self, ordered)\u001b[0m\n\u001b[1;32m     86\u001b[0m new_seed_value \u001b[38;5;241m=\u001b[39m seed_state\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ordered:\n\u001b[0;32m---> 88\u001b[0m     increment \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muint32\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     90\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39massign(seed_state \u001b[38;5;241m+\u001b[39m increment)\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;66;03m# This produces a sequence of near-unique numbers\u001b[39;00m\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;66;03m# between 0 and 1M\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/backend/tensorflow/core.py:113\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[0;34m(x, dtype, sparse)\u001b[0m\n\u001b[1;32m    111\u001b[0m         x \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(x)\n\u001b[1;32m    112\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mcast(x, dtype)\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m dtype:\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, tf\u001b[38;5;241m.\u001b[39mSparseTensor):\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1260\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1258\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1259\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1260\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch_target\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m   1262\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1263\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1264\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/tensor_conversion.py:161\u001b[0m, in \u001b[0;36mconvert_to_tensor_v2_with_dispatch\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m\u001b[38;5;241m.\u001b[39mtf_export(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconvert_to_tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[1;32m     97\u001b[0m \u001b[38;5;129m@dispatch\u001b[39m\u001b[38;5;241m.\u001b[39madd_dispatch_support\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_to_tensor_v2_with_dispatch\u001b[39m(\n\u001b[1;32m     99\u001b[0m     value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype_hint\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    100\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m tensor_lib\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m    101\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Converts the given `value` to a `Tensor`.\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \n\u001b[1;32m    103\u001b[0m \u001b[38;5;124;03m  This function converts Python objects of various types to `Tensor`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;124;03m    ValueError: If the `value` is a tensor not of given `dtype` in graph mode.\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 161\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconvert_to_tensor_v2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m      \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype_hint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_hint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/tensor_conversion.py:171\u001b[0m, in \u001b[0;36mconvert_to_tensor_v2\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Converts the given `value` to a `Tensor`.\"\"\"\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# preferred_dtype = preferred_dtype or dtype_hint\u001b[39;00m\n\u001b[0;32m--> 171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor_conversion_registry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreferred_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_hint\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/tensor_conversion_registry.py:234\u001b[0m, in \u001b[0;36mconvert\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, accepted_result_types)\u001b[0m\n\u001b[1;32m    225\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    226\u001b[0m           _add_error_prefix(\n\u001b[1;32m    227\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversion function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconversion_func\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m for type \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    230\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactual = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mret\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mbase_dtype\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    231\u001b[0m               name\u001b[38;5;241m=\u001b[39mname))\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 234\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mconversion_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_ref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[1;32m    237\u001b[0m   \u001b[38;5;28;01mcontinue\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/constant_tensor_conversion.py:29\u001b[0m, in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m constant_op  \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top\u001b[39;00m\n\u001b[1;32m     28\u001b[0m _ \u001b[38;5;241m=\u001b[39m as_ref\n\u001b[0;32m---> 29\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconstant_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/ops/weak_tensor_ops.py:142\u001b[0m, in \u001b[0;36mweak_tensor_binary_op_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    141\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mis_auto_dtype_conversion_enabled():\n\u001b[0;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m   bound_arguments \u001b[38;5;241m=\u001b[39m signature\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    144\u001b[0m   bound_arguments\u001b[38;5;241m.\u001b[39mapply_defaults()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:276\u001b[0m, in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconstant\u001b[39m(\n\u001b[1;32m    179\u001b[0m     value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConst\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    180\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[ops\u001b[38;5;241m.\u001b[39mOperation, ops\u001b[38;5;241m.\u001b[39m_EagerTensorBase]:\n\u001b[1;32m    181\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \n\u001b[1;32m    183\u001b[0m \u001b[38;5;124;03m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;124;03m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 276\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mallow_broadcast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:289\u001b[0m, in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.constant\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    288\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[0;32m--> 289\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_eager_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    291\u001b[0m const_tensor \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39m_create_graph_constant(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    292\u001b[0m     value, dtype, shape, name, verify_shape, allow_broadcast\n\u001b[1;32m    293\u001b[0m )\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m const_tensor\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:301\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constant_eager_impl\u001b[39m(\n\u001b[1;32m    298\u001b[0m     ctx, value, dtype, shape, verify_shape\n\u001b[1;32m    299\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ops\u001b[38;5;241m.\u001b[39m_EagerTensorBase:\n\u001b[1;32m    300\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a constant on the current device.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 301\u001b[0m   t \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_to_eager_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    302\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:108\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    106\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[1;32m    107\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.manifold import TSNE\nfrom sklearn.preprocessing import LabelEncoder\nfrom matplotlib import cm\nfrom matplotlib.colors import ListedColormap\n\n\n#embedding_model = models.Model(inputs=model.inputs[0], outputs=model.get_layer('embeddings').output)\n\n# Generate embeddings with 'training=False'\nembeddings = embedding_model.predict(images_np_preprocessed)\n\n# Sample image embeddings and labels\n# image_embeddings = ... (your embeddings)\n# labels_np = ... (your string labels)\n\n# Convert string labels to numeric labels\nlabel_encoder = LabelEncoder()\nnumeric_labels = label_encoder.fit_transform(labels_np)\n\n# Use t-SNE to reduce the embedding space to 2D for visualization\ntsne = TSNE(n_components=2, random_state=42)\nembeddings_2d = tsne.fit_transform(embeddings)  # Use your actual embeddings here\n\n# Create a custom color map to support 31 classes\ncolors = cm.get_cmap('tab20b', 31)  # 'tab20b' offers a distinct palette; we can define 31 colors explicitly\n\n# Plot the 2D embeddings with color based on numeric labels\nplt.figure(figsize=(10, 10))\nscatter = plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], \n                      c=numeric_labels, cmap=colors, s=20)  # Decreased marker size (s=20)\n\n# Add a color legend\nlegend1 = plt.legend(*scatter.legend_elements(), title=\"Person\")\nplt.gca().add_artist(legend1)\n\n# Set plot details\nplt.title('t-SNE of Image Embeddings (Color-coded)')\nplt.xlabel('Component 1')\nplt.ylabel('Component 2')\n\n# Show the plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-09-24T14:13:58.827109Z","iopub.execute_input":"2024-09-24T14:13:58.827781Z","iopub.status.idle":"2024-09-24T14:14:32.995838Z","shell.execute_reply.started":"2024-09-24T14:13:58.827738Z","shell.execute_reply":"2024-09-24T14:14:32.994914Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow/python/data/ops/structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 254ms/step\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_36/128802008.py:27: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n  colors = cm.get_cmap('tab20b', 31)  # 'tab20b' offers a distinct palette; we can define 31 colors explicitly\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x1000 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"markdown","source":"# Adaptive K-means","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers, models, regularizers\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models, regularizers\nimport numpy as np\n\nimport tensorflow as tf\nfrom sklearn.cluster import KMeans\ntf.config.run_functions_eagerly(True) \n\nclass KDELossLayer(tf.keras.layers.Layer):\n    def __init__(self, bandwidth=1.0, margin=2.0, num_subclusters=3, variance_threshold=0.5, **kwargs):\n        super(KDELossLayer, self).__init__(**kwargs)\n        self.bandwidth = tf.cast(bandwidth, tf.float32)\n        self.margin = tf.cast(margin, tf.float32)\n        self.num_subclusters = num_subclusters  # Number of sub-clusters for each class\n        self.variance_threshold = tf.cast(variance_threshold, tf.float32)\n\n    def call(self, inputs):\n        embeddings, labels = inputs\n\n        # Ensure embeddings are float32\n        embeddings = tf.cast(embeddings, tf.float32)\n\n        # Convert labels to one-hot encoding and integer labels\n        labels = tf.argmax(labels, axis=-1, output_type=tf.int32)\n        one_hot_labels = tf.one_hot(labels, depth=tf.reduce_max(labels) + 1)\n\n        # Compute pairwise distances for all embeddings\n        pairwise_dists = tf.norm(\n            tf.expand_dims(embeddings, 1) - tf.expand_dims(embeddings, 0), axis=-1\n        )\n\n        # Gaussian kernel for all distances (intra-class density)\n        kde_density = tf.exp(-pairwise_dists**2 / (2 * self.bandwidth**2))\n\n        # For each class, apply the mask to isolate class members (intra-class mask)\n        mask = tf.matmul(one_hot_labels, tf.transpose(one_hot_labels))\n\n        # Avoid self-contribution by masking out diagonal elements\n        mask_off_diagonal = tf.linalg.set_diag(mask, tf.zeros(tf.shape(mask)[0]))\n\n        # Compute KDE loss for each class (intra-class KDE)\n        kde_class_density = tf.reduce_sum(kde_density * mask_off_diagonal, axis=-1)\n\n        # Intra-class KDE loss\n        kde_loss = -tf.reduce_mean(tf.math.log(kde_class_density + 1e-8))\n\n        # Use map_fn to apply K-means clustering and variance penalty computation per class\n        unique_labels = tf.range(tf.reduce_max(labels) + 1)  # Get all class labels (0, 1, ..., num_classes-1)\n\n        def compute_cluster_penalty(class_label):\n            class_mask = tf.equal(labels, class_label)\n            class_embeddings = tf.boolean_mask(embeddings, class_mask)\n\n            # Perform K-means clustering on the embeddings of this class\n            if tf.shape(class_embeddings)[0] > 1:  # Ensure there's more than 1 point to analyze\n                # Temporarily convert to numpy for KMeans since TensorFlow doesn't support KMeans directly\n                class_embeddings_np = class_embeddings.numpy()  # Convert to numpy temporarily for clustering\n\n                # Perform KDE to estimate the number of peaks (and thus clusters)\n                kde = KernelDensity(bandwidth=self.bandwidth).fit(class_embeddings_np)\n                kde_scores = kde.score_samples(class_embeddings_np)\n\n                # Detect peaks in KDE\n                peaks, _ = scipy.signal.find_peaks(kde_scores)\n                num_peaks = len(peaks)\n                \n                # Set the number of clusters based on the number of peaks\n                num_clusters = min(self.num_subclusters, num_peaks) if num_peaks > 0 else 1\n\n                if num_clusters > 1:\n                    kmeans = KMeans(n_clusters=num_clusters, n_init=10, random_state=42)\n                    kmeans.fit(class_embeddings_np)  # Run K-means on the embeddings\n\n                    centroids = tf.constant(kmeans.cluster_centers_, dtype=tf.float32)\n                    assignments = kmeans.labels_\n\n                    # Compute variance for each sub-cluster\n                    variance_penalty = 0.0\n                    for i in range(num_clusters):\n                        cluster_points = tf.boolean_mask(class_embeddings, assignments == i)\n                        centroid = centroids[i]\n\n                        # Variance: Mean squared distance to the centroid\n                        variance = tf.reduce_mean(tf.square(cluster_points - centroid))\n\n                        # Apply variance penalty if it exceeds the threshold\n                        if variance > self.variance_threshold:\n                            variance_penalty += variance - self.variance_threshold\n\n                    return variance_penalty\n            return 0.0\n\n        # Compute total variance penalty across all unique labels\n        total_variance_penalty = tf.reduce_sum(tf.map_fn(compute_cluster_penalty, unique_labels, dtype=tf.float32))\n\n        # Add margin-based inter-class separation\n        inter_class_mask = 1.0 - mask  # Inter-class mask (where classes are different)\n        inter_class_dists = pairwise_dists * inter_class_mask\n        margin_penalty = tf.maximum(0.0, self.margin - inter_class_dists)  # Penalty for distances below margin\n        inter_class_loss = tf.reduce_mean(margin_penalty)\n\n        # Total loss: Intra-class (KDE loss) + Inter-class (Margin loss) + Variance penalty\n        total_loss = kde_loss + inter_class_loss + total_variance_penalty\n\n        return total_loss\n\n    def compute_output_shape(self, input_shape):\n        return (input_shape[0][0], 1)\n\ndef build_vgg19_kde_loss(input_shape, num_classes, embedding_dim, dropout_rate, weight_decay):\n    # Define input layers\n    inputs = layers.Input(shape=input_shape, name='input')\n    labels_input = layers.Input(shape=(num_classes,), name='labels_input', dtype='float32')\n\n    # Define VGG19 backbone (without the top layers)\n    base_model = tf.keras.applications.VGG19(include_top=False, input_shape=input_shape, weights='imagenet')\n\n    for layer in base_model.layers[:15]:  # Freeze the first 15 layers (you can adjust this number)\n        layer.trainable = False\n    \n    # Flatten the output of the VGG19 backbone\n    x = base_model.output\n    x = layers.Flatten()(x)\n    \n    x = layers.Dense(1231, activation='swish', kernel_regularizer=regularizers.l2(weight_decay), bias_regularizer=regularizers.l2(0.01))(x)\n    x = layers.Dropout(dropout_rate)(x)\n    x = layers.Dense(300, activation='swish', kernel_regularizer=regularizers.l2(weight_decay), bias_regularizer=regularizers.l2(0.01))(x)\n    x = layers.Dropout(dropout_rate)(x)\n    x = layers.Dense(75, activation='swish', kernel_regularizer=regularizers.l2(weight_decay), bias_regularizer=regularizers.l2(0.01))(x)\n    x = layers.Dropout(dropout_rate)(x)\n    x = layers.Dense(1003, activation='swish', kernel_regularizer=regularizers.l2(weight_decay), bias_regularizer=regularizers.l2(0.01))(x)\n    x = layers.Dense(embedding_dim, activation='swish')(x)\n\n    # Define the embedding model\n    embedding_model = models.Model(inputs=base_model.input, outputs=x, name='embedding_model')\n\n    # Generate embeddings for the inputs\n    embedding = embedding_model(inputs)\n\n    # Define logits for classification using the embedding\n    logits = layers.Dense(num_classes, activation='softmax', name='classification_layer')(embedding)\n\n    # Define the custom KDE loss layer\n    kde_loss_layer = KDELossLayer()\n    kde_loss_output = kde_loss_layer([embedding, labels_input])\n\n    # Define the full model with classification and KDE loss\n    full_model = models.Model(\n        inputs=[inputs, labels_input],\n        outputs=[logits, kde_loss_output],\n        name='full_model'\n    )\n\n    return embedding_model, full_model\n\ndef train_and_evaluate(model, train_generator, val_generator, steps_per_epoch, validation_steps, epochs, center_loss_weight, learning_rate):\n    optimizer = tf.keras.optimizers.RMSprop(learning_rate)\n\n    history = {\n        \"train_loss\": [],\n        \"train_class_loss\": [],\n        \"train_center_loss\": [],\n        \"train_acc\": [],\n        \"val_class_loss\": [],\n        \"val_center_loss\": [],\n        \"val_acc\": []\n    }\n\n    @tf.function\n    def train_step(inputs, labels):\n        with tf.GradientTape() as tape:\n            logits, center_loss = model([inputs, labels], training=True)\n            classification_loss = tf.keras.losses.CategoricalCrossentropy()(labels, logits)\n            total_loss = classification_loss + center_loss_weight * center_loss\n\n        gradients = tape.gradient(total_loss, model.trainable_variables)\n        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n\n        predictions = tf.argmax(logits, axis=-1)\n        labels_true = tf.argmax(labels, axis=-1)\n        train_acc = tf.reduce_mean(tf.cast(tf.equal(predictions, labels_true), tf.float32))\n\n        return total_loss, classification_loss, center_loss, train_acc\n\n    @tf.function\n    def eval_step(inputs, labels):\n        logits, center_loss = model([inputs, labels], training=False)\n        classification_loss = tf.keras.losses.CategoricalCrossentropy()(labels, logits)\n\n        predictions = tf.argmax(logits, axis=-1)\n        labels_true = tf.argmax(labels, axis=-1)\n        accuracy = tf.reduce_mean(tf.cast(tf.equal(predictions, labels_true), tf.float32))\n\n        return classification_loss, center_loss, accuracy\n\n    for epoch in range(epochs):\n        print(f\"Epoch {epoch+1}/{epochs}\")\n\n        # Training loop\n        epoch_loss, epoch_class_loss, epoch_center_loss, epoch_acc = 0, 0, 0, 0\n        for step in range(steps_per_epoch):\n            inputs_batch, labels_batch = next(train_generator)\n            loss, class_loss, center_loss, acc = train_step(inputs_batch, labels_batch)\n            epoch_loss += loss\n            epoch_class_loss += class_loss\n            epoch_center_loss += center_loss\n            epoch_acc += acc\n\n        epoch_loss /= steps_per_epoch\n        epoch_class_loss /= steps_per_epoch\n        epoch_center_loss /= steps_per_epoch\n        epoch_acc /= steps_per_epoch\n\n        print(f\"Train Loss: {epoch_loss:.4f}, Class Loss: {epoch_class_loss:.4f}, Center Loss: {epoch_center_loss:.4f}, Acc: {epoch_acc:.4f}\")\n\n        history[\"train_loss\"].append(epoch_loss)\n        history[\"train_class_loss\"].append(epoch_class_loss)\n        history[\"train_center_loss\"].append(epoch_center_loss)\n        history[\"train_acc\"].append(epoch_acc)\n\n        # Validation loop\n        val_class_loss, val_center_loss, val_acc = 0, 0, 0\n        for step in range(validation_steps):\n            inputs_batch, labels_batch = next(val_generator)\n            class_loss, center_loss, acc = eval_step(inputs_batch, labels_batch)\n            val_class_loss += class_loss\n            val_center_loss += center_loss\n            val_acc += acc\n\n        val_class_loss /= validation_steps\n        val_center_loss /= validation_steps\n        val_acc /= validation_steps\n\n        print(f\"Val Class Loss: {val_class_loss:.4f}, Val Center Loss: {val_center_loss:.4f}, Val Acc: {val_acc:.4f}\")\n\n        history[\"val_class_loss\"].append(val_class_loss)\n        history[\"val_center_loss\"].append(val_center_loss)\n        history[\"val_acc\"].append(val_acc)\n\n    return history\n\n# Initialize ImageDataGenerator with augmentation options (without rescaling)\ntrain_datagen = ImageDataGenerator(\n    rotation_range=20,           # Randomly rotate images by 20 degrees\n    width_shift_range=0.2,       # Randomly shift images horizontally\n    height_shift_range=0.2,      # Randomly shift images vertically\n    shear_range=0.2,             # Shear transformation\n    zoom_range=0.2,              # Zoom in/out\n    horizontal_flip=True,        # Random horizontal flipping\n    fill_mode='nearest'          # Filling pixels after transformations\n)\n\n# Example usage with specified values\ninput_shape = (224, 224, 3)        # Input shape for images (224x224 RGB)\nnum_classes = 31                   # Number of classes in the dataset\nembedding_dim = 768              # Dimensionality of the embedding space\ndropout_rate = 0.1               # Dropout rate for regularization\nweight_decay = 0.05 #0.005            # L2 regularization weight\ncenter_loss_weight = 0.1 #0.0001          # Weight for center loss\nlearning_rate = 1e-4               # Learning rate for the optimizer\nbatch_size = 32                    # Batch size for training\nepochs = 75                      # Number of epochs to train\n\nval_datagen = ImageDataGenerator()  # No additional augmentations for validation\n\n# Load and augment training data\ntrain_generator = train_datagen.flow(X_train, y_train, batch_size=batch_size)\n\n# Load validation data\nval_generator = val_datagen.flow(X_val, y_val, batch_size=batch_size)\n\nsteps_per_epoch = len(X_train) // batch_size\nvalidation_steps = len(X_val)  // batch_size\n\n# Build the model using VGG19 and center loss\nembedding_model, full_model = build_vgg19_kde_loss(input_shape, num_classes, embedding_dim, dropout_rate, weight_decay)\n# Train the model using data generators\nhistory = train_and_evaluate(full_model, train_generator, val_generator, steps_per_epoch, validation_steps, epochs, center_loss_weight, learning_rate)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-24T15:12:20.717724Z","iopub.execute_input":"2024-09-24T15:12:20.718203Z"},"trusted":true},"execution_count":null,"outputs":[]}]}