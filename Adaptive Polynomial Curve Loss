{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Adaptive Polynomial Curve Loss for Varied Distribution Clusters in Deep Face Recognition                                  \n* Adaptive Polynomial Curve Loss: The core idea of representing class centers as polynomial curves.\n* For Varied Distribution Clusters: Highlights the ability to handle complex, varied distributions within each class.\n* For Deep Face Recognition: Specifies the application area, making it clear that the approach is designed for deep face recognition tasks.","metadata":{}},{"cell_type":"markdown","source":"# 1. Dataset    \n## Kaggle: Face Recognition Dataset\n* Face Data of 31 different classes\n* unique values: 2562\n* link: https://www.kaggle.com/datasets/vasukipatel/face-recognition-dataset \n","metadata":{}},{"cell_type":"markdown","source":"### 1.1 Dataset directory","metadata":{}},{"cell_type":"code","source":"# Set directories\nimport os\nws_dir = '/kaggle/input'\ndataset_dir = os.path.join(ws_dir, 'dataset01')\nfaces_dir = os.path.join(dataset_dir, 'faces')","metadata":{"execution":{"iopub.status.busy":"2024-09-22T14:31:56.412078Z","iopub.execute_input":"2024-09-22T14:31:56.412428Z","iopub.status.idle":"2024-09-22T14:31:56.434284Z","shell.execute_reply.started":"2024-09-22T14:31:56.412388Z","shell.execute_reply":"2024-09-22T14:31:56.433384Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"### 1.2 Dataset as numpy array  \n\n* Resize the original image to (224,224,3) when creating numpy array","metadata":{}},{"cell_type":"code","source":"import cv2\nimport numpy as np\n\nimages = []\nlabels = []\n\n# Loop over each person directory in the faces directory\nfor person_name in os.listdir(faces_dir):\n    person_dir = os.path.join(faces_dir, person_name)\n\n    # Check if it is a directory (and not a file)\n    if os.path.isdir(person_dir):\n        # Loop over each image in the person's directory\n        for image_name in os.listdir(person_dir):\n            image_path = os.path.join(person_dir, image_name)\n\n            # Load image using OpenCV\n            image = cv2.imread(image_path)\n\n            # Optionally resize images to a standard size (e.g., 224x224)\n            image = cv2.resize(image, (224, 224))\n\n            # Convert the image to RGB (OpenCV loads images in BGR format by default)\n            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n            # Append image and corresponding label to lists\n            images.append(image)\n            labels.append(person_name)  # The person's name is used as the label\n\n# Convert lists to NumPy arrays\nimages_np = np.array(images)\nlabels_np = np.array(labels)\n\n# Verify the shapes\nprint(f'Images shape: {images_np.shape}')  # (num_images, 224, 224, 3)\nprint(f'Labels shape: {labels_np.shape}')  # (num_images,)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-22T14:32:26.393422Z","iopub.execute_input":"2024-09-22T14:32:26.394382Z","iopub.status.idle":"2024-09-22T14:32:37.501844Z","shell.execute_reply.started":"2024-09-22T14:32:26.394310Z","shell.execute_reply":"2024-09-22T14:32:37.500754Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Images shape: (2562, 224, 224, 3)\nLabels shape: (2562,)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### 1.3 Preprocess dataset                                                                                                  \n* Preprocess using VGG19 preprocess_input\n* Convert label to Onehot encoding\n* Split dataset into train, test and validation","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.applications.vgg19 import preprocess_input\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nimport numpy as np\n\n# Assuming images_np and labels_np are provided\n# images_np.shape = (num_samples, height, width, channels)\n# labels_np.shape = (num_samples,)\n\n# Preprocess images for VGG19\nimages_np_preprocessed = preprocess_input(images_np)\n\n# One-hot encode labels\none_hot_encoder = OneHotEncoder(sparse=False)\nlabels_np_onehot = one_hot_encoder.fit_transform(labels_np.reshape(-1, 1))\n\n# Split into training, validation, and test sets\nX_train, X_temp, y_train, y_temp = train_test_split(images_np_preprocessed, labels_np_onehot, test_size=0.3, random_state=42)\nX_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n\nprint(f\"Train set: {X_train.shape}, {y_train.shape}\")\nprint(f\"Validation set: {X_val.shape}, {y_val.shape}\")\nprint(f\"Test set: {X_test.shape}, {y_test.shape}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-22T14:35:35.034177Z","iopub.execute_input":"2024-09-22T14:35:35.034649Z","iopub.status.idle":"2024-09-22T14:35:52.943618Z","shell.execute_reply.started":"2024-09-22T14:35:35.034603Z","shell.execute_reply":"2024-09-22T14:35:52.942085Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train set: (1793, 224, 224, 3), (1793, 31)\nValidation set: (384, 224, 224, 3), (384, 31)\nTest set: (385, 224, 224, 3), (385, 31)\n","output_type":"stream"}]}]}